{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8acacc73",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "Enhance the DeBerta in regards to the recall, as, even though it was \n",
    "overall the best model from our baselines, it had a low recall.\n",
    "Hence, we add some additional decision logic when DeBerta is predicting \n",
    "a sample to be negative.\n",
    "\n",
    "We are reducing the amount of false negatives by adding additional logic\n",
    "to negative predictions to possibly swap them to a positive prediction,\n",
    "given that the models after the DeBerta all agree on a positive prediction.\n",
    "\n",
    "This approach will increase the recall (as we do less negative predictions), \n",
    "but will also increase the amount of false positives (as we doing more positive\n",
    "predictions overall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c190a6e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28995f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars\n",
    "from polars import DataFrame, Series, col\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from label_legends.deberta import load_dataset, load_deberta, load_dataset\n",
    "from label_legends.preprocess import holdout, load_data, load_test, transform, load_own\n",
    "from label_legends.female import predict_female\n",
    "from label_legends.swears_negative import predict_swear, predict_negative_sentiment\n",
    "from label_legends.result import calculate_scores\n",
    "from label_legends.util import ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77741141",
   "metadata": {},
   "source": [
    "# Use Deberta to create initial predictions:\n",
    "We fine tune the DeBerta on our train set as we \n",
    "did for the baseline and report the performance of\n",
    "DeBerta alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70fec1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/home/lukas/.local/share/uv/python/cpython-3.12.5-linux-x86_64-gnu/lib/python3.12/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
       "In addition, using fork() with Python in general is a recipe for mysterious\n",
       "deadlocks and crashes.\n",
       "\n",
       "The most likely reason you are seeing this error is because you are using the\n",
       "multiprocessing module on Linux, which uses fork() by default. This will be\n",
       "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
       "\n",
       "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
       "\n",
       "  self.pid = os.fork()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
       "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/lukas/.local/share/uv/python/cpython-3.12.5-linux-x86_64-gnu/lib/python3.12/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
       "In addition, using fork() with Python in general is a recipe for mysterious\n",
       "deadlocks and crashes.\n",
       "\n",
       "The most likely reason you are seeing this error is because you are using the\n",
       "multiprocessing module on Linux, which uses fork() by default. This will be\n",
       "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
       "\n",
       "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
       "\n",
       "  self.pid = os.fork()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/lukas/Programming/uni/nlp-ie-label-legends/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deberta = load_deberta()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855c23f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "DeBerta is trained for 5 epochs, for details look into `deberta.py` in our package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13f1c998",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/home/lukas/Programming/uni/nlp-ie-label-legends/src/label_legends/deberta.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
       "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='9190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/9190 : < :, Epoch 0.00/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/lukas/Programming/uni/nlp-ie-label-legends/src/label_legends/deberta.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
       "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/lukas/Programming/uni/nlp-ie-label-legends/src/label_legends/deberta.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
       "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/lukas/Programming/uni/nlp-ie-label-legends/src/label_legends/deberta.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
       "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/lukas/Programming/uni/nlp-ie-label-legends/src/label_legends/deberta.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
       "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ğŸƒ View run ./results at: https://mlflow.mahluke.page/#/experiments/0/runs/84afb3bcc4784f47b2b4d4b838223629\n",
       "ğŸ§ª View experiment at: https://mlflow.mahluke.page/#/experiments/0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_runtime': 3930.9354,\n",
       " 'train_samples_per_second': 37.396,\n",
       " 'train_steps_per_second': 2.338,\n",
       " 'total_flos': 7025499503316000.0,\n",
       " 'train_loss': 0.2813671406776005,\n",
       " 'epoch': 5.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_out = deberta.train()\n",
    "train_out.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0851f2c6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/home/lukas/Programming/uni/nlp-ie-label-legends/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/lukas/Programming/uni/nlp-ie-label-legends/src/label_legends/deberta.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
       "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/4 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.22100908, -0.3849549 ],\n",
       "       [ 0.20448087, -0.35345423],\n",
       "       [ 1.4354323 , -1.9412558 ],\n",
       "       [ 1.3453149 , -1.7552105 ],\n",
       "       [ 1.6932449 , -2.0605826 ],\n",
       "       [ 1.330438  , -1.7849141 ],\n",
       "       [ 0.00815822, -0.13858354],\n",
       "       [ 1.4483907 , -1.8163158 ],\n",
       "       [ 1.6816638 , -2.0947795 ],\n",
       "       [ 1.3424137 , -1.6290814 ],\n",
       "       [ 1.4861088 , -1.8607656 ],\n",
       "       [ 1.5169125 , -1.922798  ],\n",
       "       [ 1.5939958 , -1.9327121 ],\n",
       "       [ 1.6717114 , -2.0650768 ],\n",
       "       [ 1.3191297 , -1.8152466 ],\n",
       "       [ 1.5501674 , -1.966885  ],\n",
       "       [ 0.01321473, -0.18853423],\n",
       "       [ 0.04816356, -0.10234571],\n",
       "       [ 0.5855616 , -0.77393943],\n",
       "       [ 0.6758357 , -0.7819318 ],\n",
       "       [ 0.32601324, -0.5094394 ],\n",
       "       [ 0.9591873 , -1.4126728 ],\n",
       "       [ 1.2254938 , -1.559727  ],\n",
       "       [ 1.1200161 , -1.5564845 ],\n",
       "       [ 1.4277071 , -1.8830895 ],\n",
       "       [ 1.1576838 , -1.5392526 ],\n",
       "       [ 1.2855673 , -1.7444466 ],\n",
       "       [ 1.6091292 , -2.0526745 ],\n",
       "       [ 1.2629819 , -1.7846802 ],\n",
       "       [ 1.6060214 , -1.9787896 ],\n",
       "       [ 0.12762664, -0.21555841],\n",
       "       [-1.1038963 ,  1.6185089 ],\n",
       "       [ 1.5045668 , -1.9714092 ],\n",
       "       [ 1.344254  , -1.7904613 ],\n",
       "       [-0.28402743,  0.29446483],\n",
       "       [ 1.6148539 , -1.9929911 ],\n",
       "       [ 1.2172922 , -1.6921872 ],\n",
       "       [ 0.716068  , -0.87648004],\n",
       "       [-0.08759738, -0.02998737],\n",
       "       [ 1.1478368 , -1.5080673 ],\n",
       "       [ 1.4755208 , -1.8710867 ],\n",
       "       [ 0.2697307 , -0.38278404],\n",
       "       [ 1.1380422 , -1.4219965 ],\n",
       "       [-0.6642607 ,  0.9785639 ],\n",
       "       [ 1.3577926 , -1.786916  ],\n",
       "       [ 1.4797672 , -1.8579296 ],\n",
       "       [-0.37548754,  0.3801272 ],\n",
       "       [ 0.14477846, -0.22068858],\n",
       "       [ 1.229924  , -1.581849  ],\n",
       "       [ 0.12665534, -0.28728414],\n",
       "       [ 1.0520632 , -1.1772873 ],\n",
       "       [ 1.3390183 , -1.8274107 ],\n",
       "       [ 1.0846866 , -1.4712718 ],\n",
       "       [ 1.6058577 , -1.9827149 ],\n",
       "       [-0.3570769 ,  0.38880125],\n",
       "       [-1.123449  ,  1.6934385 ],\n",
       "       [ 1.1928736 , -1.492464  ],\n",
       "       [-0.8984653 ,  1.4082024 ],\n",
       "       [ 1.3200561 , -1.7521163 ],\n",
       "       [ 1.5726814 , -2.0219831 ]], dtype=float32), label_ids=array([1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0]), metrics={'test_loss': 0.7870756983757019, 'test_precision': 0.875, 'test_recall': 0.25, 'test_fscore': 0.3888888888888889, 'test_accuracy': 0.6333333333333333, 'test_tp': 7, 'test_tn': 31, 'test_fp': 1, 'test_fn': 21, 'test_runtime': 0.3238, 'test_samples_per_second': 185.291, 'test_steps_per_second': 12.353})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = load_own() # replace with `load_test()` if test data should be used\n",
    "test_transformed = transform(test)\n",
    "deberta_prediction = deberta.predict(load_dataset(test_transformed[\"text\"].to_list(), test_transformed[\"label\"].to_list()))\n",
    "deberta_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21b9bfc9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>label</th><th>deberta</th></tr><tr><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>1</td><td>0</td></tr><tr><td>2</td><td>1</td><td>0</td></tr><tr><td>3</td><td>0</td><td>0</td></tr><tr><td>4</td><td>1</td><td>0</td></tr><tr><td>5</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ id  â”† label â”† deberta â”‚\n",
       "â”‚ --- â”† ---   â”† ---     â”‚\n",
       "â”‚ i64 â”† i64   â”† i64     â”‚\n",
       "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 1   â”† 1     â”† 0       â”‚\n",
       "â”‚ 2   â”† 1     â”† 0       â”‚\n",
       "â”‚ 3   â”† 0     â”† 0       â”‚\n",
       "â”‚ 4   â”† 1     â”† 0       â”‚\n",
       "â”‚ 5   â”† 0     â”† 0       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = DataFrame({\"id\": test[\"id\"], \"label\": deberta_prediction.label_ids, \"deberta\": np.argmax(deberta_prediction.predictions, axis=1)})\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e08b531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision:\t0.8750\n",
       "recall:\t\t0.2500\n",
       "fscore:\t\t0.3889\n",
       "accuracy:\t0.6333\n",
       "tn: 31\t fp: 1\n",
       "fn: 21\t tp: 7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_deberta = calculate_scores(predictions[\"label\"], predictions[\"deberta\"])\n",
    "scores_deberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac33603",
   "metadata": {},
   "source": [
    "# Post-Process negative predictions\n",
    "In order to improve the base results from above we employ 3 models.\n",
    "If all of those models predict positive, our ensemble swaps the negative \n",
    "prediction to positive, which allows us to achieve a higher recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d35450d",
   "metadata": {},
   "source": [
    "## Predict if sentence is referencing a female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4246bbf6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>type</th><th>label</th><th>deberta</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>&quot;fn&quot;</td><td>1</td><td>0</td></tr><tr><td>2</td><td>&quot;fn&quot;</td><td>1</td><td>0</td></tr><tr><td>3</td><td>&quot;tn&quot;</td><td>0</td><td>0</td></tr><tr><td>4</td><td>&quot;fn&quot;</td><td>1</td><td>0</td></tr><tr><td>5</td><td>&quot;tn&quot;</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ id  â”† type â”† label â”† deberta â”‚\n",
       "â”‚ --- â”† ---  â”† ---   â”† ---     â”‚\n",
       "â”‚ i64 â”† str  â”† i64   â”† i64     â”‚\n",
       "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 1   â”† fn   â”† 1     â”† 0       â”‚\n",
       "â”‚ 2   â”† fn   â”† 1     â”† 0       â”‚\n",
       "â”‚ 3   â”† tn   â”† 0     â”† 0       â”‚\n",
       "â”‚ 4   â”† fn   â”† 1     â”† 0       â”‚\n",
       "â”‚ 5   â”† tn   â”† 0     â”† 0       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def assign_type(prediction: int, label: str):\n",
    "    if prediction == 0:\n",
    "        if label == \"not sexist\":\n",
    "            return \"tn\"\n",
    "        return \"fn\"\n",
    "    if label == \"sexist\":\n",
    "        return \"tp\"\n",
    "    return \"fp\"\n",
    "\n",
    "\n",
    "predictions = predictions.join(test, on=\"id\").with_columns(polars.struct([\"deberta\", \"label_sexist\"]).map_elements(lambda x: assign_type(x['deberta'],x['label_sexist']), return_dtype=polars.String).alias(\"type\")).select([\"id\", \"type\", \"label\", \"deberta\"])\n",
    "\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6da64",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Add the predictions whether a text is about a female or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3504dec2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/tmp/ipykernel_243218/2309025452.py:8: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
       "  predictions = predictions.join(predict_female(test), on=\"id\").with_columns(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def alt_on_neg_pred(prediction: int, alternative: int):\n",
    "    \"\"\"Use the alternative if prediction is negative\"\"\"\n",
    "    if prediction == 1:\n",
    "        return 1\n",
    "    return alternative\n",
    "\n",
    "\n",
    "predictions = predictions.join(predict_female(test), on=\"id\").with_columns(\n",
    "    polars.struct([\"female\", \"deberta\"]).map_elements(lambda x: alt_on_neg_pred(x[\"deberta\"], x[\"female\"])).alias(\"pred_female\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104efdda",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We see that the prediction of most false positives is reconsidered, as those contain some female phrase. However, many of true negatives are also reconsidered, leading to a potentially worse precision. As we are focusing on increasing the recall, this is a trade-off we have to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7f4ed6c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>female</th><th>type</th><th>samples</th><th>perc</th></tr><tr><td>i32</td><td>str</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>&quot;tp&quot;</td><td>6</td><td>0.857143</td></tr><tr><td>1</td><td>&quot;tn&quot;</td><td>7</td><td>0.225806</td></tr><tr><td>1</td><td>&quot;fn&quot;</td><td>13</td><td>0.619048</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 4)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ female â”† type â”† samples â”† perc     â”‚\n",
       "â”‚ ---    â”† ---  â”† ---     â”† ---      â”‚\n",
       "â”‚ i32    â”† str  â”† u32     â”† f64      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 1      â”† tp   â”† 6       â”† 0.857143 â”‚\n",
       "â”‚ 1      â”† tn   â”† 7       â”† 0.225806 â”‚\n",
       "â”‚ 1      â”† fn   â”† 13      â”† 0.619048 â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions.group_by(\"female\", \"type\").len().with_columns((polars.col(\"len\") / polars.sum(\"len\").over(\"type\")).alias(\"perc\")).filter(col(\"female\")==1).sort(\"len\").rename({\"len\": \"samples\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd956d8",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4bcf56b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>type</th><th>label</th><th>deberta</th><th>female</th><th>pred_female</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i32</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>&quot;fn&quot;</td><td>1</td><td>0</td><td>1</td><td>1</td></tr><tr><td>2</td><td>&quot;fn&quot;</td><td>1</td><td>0</td><td>1</td><td>1</td></tr><tr><td>3</td><td>&quot;tn&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>4</td><td>&quot;fn&quot;</td><td>1</td><td>0</td><td>1</td><td>1</td></tr><tr><td>5</td><td>&quot;tn&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ id  â”† type â”† label â”† deberta â”† female â”† pred_female â”‚\n",
       "â”‚ --- â”† ---  â”† ---   â”† ---     â”† ---    â”† ---         â”‚\n",
       "â”‚ i64 â”† str  â”† i64   â”† i64     â”† i32    â”† i64         â”‚\n",
       "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 1   â”† fn   â”† 1     â”† 0       â”† 1      â”† 1           â”‚\n",
       "â”‚ 2   â”† fn   â”† 1     â”† 0       â”† 1      â”† 1           â”‚\n",
       "â”‚ 3   â”† tn   â”† 0     â”† 0       â”† 0      â”† 0           â”‚\n",
       "â”‚ 4   â”† fn   â”† 1     â”† 0       â”† 1      â”† 1           â”‚\n",
       "â”‚ 5   â”† tn   â”† 0     â”† 0       â”† 0      â”† 0           â”‚\n",
       "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4c6bb8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "If we would only use 'female' without some additional measurements, we would increase our recall considerably to over 95%, which comes at the cost of precision and f-score, which are drastically decreased. In order to not worsen the model that strongly overall, we add additional measurements to decide when to change a negative prediction by Deberta to a positive one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43641401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision:\t0.7143\n",
       "recall:\t\t0.7143\n",
       "fscore:\t\t0.7143\n",
       "accuracy:\t0.7333\n",
       "tn: 24\t fp: 8\n",
       "fn: 8\t tp: 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_female = calculate_scores(predictions[\"label\"], predictions[\"pred_female\"])\n",
    "scores_female"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5fe5d2",
   "metadata": {},
   "source": [
    "## Sentiment analysis\n",
    "Predict if text has a negative connotation. If true, and also targeted towards a female, predict the sample to be sexist.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc9b873d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/tmp/ipykernel_243218/120385903.py:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
       "  predictions = predictions.join(predict_negative_sentiment(test), on=\"id\").with_columns(polars.struct([\"negative\", \"deberta\"]).map_elements(lambda x: alt_on_neg_pred(x[\"deberta\"], x[\"negative\"])).alias(\"pred_negative\"))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>type</th><th>label</th><th>deberta</th><th>female</th><th>pred_female</th><th>negative</th><th>pred_negative</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i32</td><td>i64</td><td>i32</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>&quot;fn&quot;</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>2</td><td>&quot;fn&quot;</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>3</td><td>&quot;tn&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td></tr><tr><td>4</td><td>&quot;fn&quot;</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>5</td><td>&quot;tn&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ id  â”† type â”† label â”† deberta â”† female â”† pred_female â”† negative â”† pred_negative â”‚\n",
       "â”‚ --- â”† ---  â”† ---   â”† ---     â”† ---    â”† ---         â”† ---      â”† ---           â”‚\n",
       "â”‚ i64 â”† str  â”† i64   â”† i64     â”† i32    â”† i64         â”† i32      â”† i64           â”‚\n",
       "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 1   â”† fn   â”† 1     â”† 0       â”† 1      â”† 1           â”† 0        â”† 0             â”‚\n",
       "â”‚ 2   â”† fn   â”† 1     â”† 0       â”† 1      â”† 1           â”† 0        â”† 0             â”‚\n",
       "â”‚ 3   â”† tn   â”† 0     â”† 0       â”† 0      â”† 0           â”† 1        â”† 1             â”‚\n",
       "â”‚ 4   â”† fn   â”† 1     â”† 0       â”† 1      â”† 1           â”† 0        â”† 0             â”‚\n",
       "â”‚ 5   â”† tn   â”† 0     â”† 0       â”† 0      â”† 0           â”† 1        â”† 1             â”‚\n",
       "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = predictions.join(predict_negative_sentiment(test), on=\"id\").with_columns(polars.struct([\"negative\", \"deberta\"]).map_elements(lambda x: alt_on_neg_pred(x[\"deberta\"], x[\"negative\"])).alias(\"pred_negative\"))\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d57aa8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>negative</th><th>type</th><th>female</th><th>samples</th><th>perc</th></tr><tr><td>i32</td><td>str</td><td>i32</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>&quot;fn&quot;</td><td>0</td><td>2</td><td>0.095238</td></tr><tr><td>1</td><td>&quot;fn&quot;</td><td>1</td><td>3</td><td>0.142857</td></tr><tr><td>0</td><td>&quot;fn&quot;</td><td>0</td><td>6</td><td>0.285714</td></tr><tr><td>0</td><td>&quot;fn&quot;</td><td>1</td><td>10</td><td>0.47619</td></tr><tr><td>1</td><td>&quot;tn&quot;</td><td>1</td><td>2</td><td>0.064516</td></tr><tr><td>0</td><td>&quot;tn&quot;</td><td>1</td><td>5</td><td>0.16129</td></tr><tr><td>1</td><td>&quot;tn&quot;</td><td>0</td><td>9</td><td>0.290323</td></tr><tr><td>0</td><td>&quot;tn&quot;</td><td>0</td><td>15</td><td>0.483871</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 5)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ negative â”† type â”† female â”† samples â”† perc     â”‚\n",
       "â”‚ ---      â”† ---  â”† ---    â”† ---     â”† ---      â”‚\n",
       "â”‚ i32      â”† str  â”† i32    â”† u32     â”† f64      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 1        â”† fn   â”† 0      â”† 2       â”† 0.095238 â”‚\n",
       "â”‚ 1        â”† fn   â”† 1      â”† 3       â”† 0.142857 â”‚\n",
       "â”‚ 0        â”† fn   â”† 0      â”† 6       â”† 0.285714 â”‚\n",
       "â”‚ 0        â”† fn   â”† 1      â”† 10      â”† 0.47619  â”‚\n",
       "â”‚ 1        â”† tn   â”† 1      â”† 2       â”† 0.064516 â”‚\n",
       "â”‚ 0        â”† tn   â”† 1      â”† 5       â”† 0.16129  â”‚\n",
       "â”‚ 1        â”† tn   â”† 0      â”† 9       â”† 0.290323 â”‚\n",
       "â”‚ 0        â”† tn   â”† 0      â”† 15      â”† 0.483871 â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions.group_by(\"negative\", \"type\", \"female\").len().with_columns((polars.col(\"len\") / polars.sum(\"len\").over(\"type\")).alias(\"perc\")).filter(col(\"type\").is_in([\"fn\", \"tn\"])).sort(\"len\").rename({\"len\": \"samples\"}).sort(\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "384b16bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision:\t0.5000\n",
       "recall:\t\t0.4286\n",
       "fscore:\t\t0.4615\n",
       "accuracy:\t0.5333\n",
       "tn: 20\t fp: 12\n",
       "fn: 16\t tp: 12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_negative = calculate_scores(predictions[\"label\"], predictions[\"pred_negative\"])\n",
    "scores_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb693d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Combine female & negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38229baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/tmp/ipykernel_243218/730595171.py:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
       "  predictions = predictions.with_columns(polars.struct([\"pred_negative\", \"pred_female\"]).map_elements(lambda x: x[\"pred_negative\"] and x[\"pred_female\"]).alias(\"pred_female_negative\"))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = predictions.with_columns(polars.struct([\"pred_negative\", \"pred_female\"]).map_elements(lambda x: x[\"pred_negative\"] and x[\"pred_female\"]).alias(\"pred_female_negative\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26793bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision:\t0.7692\n",
       "recall:\t\t0.3571\n",
       "fscore:\t\t0.4878\n",
       "accuracy:\t0.6500\n",
       "tn: 29\t fp: 3\n",
       "fn: 18\t tp: 10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_female_negative = calculate_scores(predictions[\"label\"], predictions[\"pred_female_negative\"])\n",
    "scores_female_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5b385e",
   "metadata": {},
   "source": [
    "## Bad words\n",
    "Check if text contains a 'bad word', if so, predict the sample to be sexist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "449afdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/tmp/ipykernel_243218/1739650169.py:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
       "  predictions = predictions.join(predict_swear(test), on=\"id\").with_columns(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = predictions.join(predict_swear(test), on=\"id\").with_columns(\n",
    "    polars.struct([\"swear\", \"deberta\"]).map_elements(lambda x: alt_on_neg_pred(x[\"deberta\"], x[\"swear\"])).alias(\"pred_swear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87efdd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>negative</th><th>swear</th><th>type</th><th>samples</th><th>perc</th></tr><tr><td>i32</td><td>i32</td><td>str</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>1</td><td>&quot;fn&quot;</td><td>1</td><td>0.047619</td></tr><tr><td>1</td><td>1</td><td>&quot;fn&quot;</td><td>1</td><td>0.047619</td></tr><tr><td>0</td><td>1</td><td>&quot;tn&quot;</td><td>2</td><td>0.064516</td></tr><tr><td>1</td><td>0</td><td>&quot;fn&quot;</td><td>4</td><td>0.190476</td></tr><tr><td>1</td><td>0</td><td>&quot;tn&quot;</td><td>11</td><td>0.354839</td></tr><tr><td>0</td><td>0</td><td>&quot;fn&quot;</td><td>15</td><td>0.714286</td></tr><tr><td>0</td><td>0</td><td>&quot;tn&quot;</td><td>18</td><td>0.580645</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 5)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ negative â”† swear â”† type â”† samples â”† perc     â”‚\n",
       "â”‚ ---      â”† ---   â”† ---  â”† ---     â”† ---      â”‚\n",
       "â”‚ i32      â”† i32   â”† str  â”† u32     â”† f64      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0        â”† 1     â”† fn   â”† 1       â”† 0.047619 â”‚\n",
       "â”‚ 1        â”† 1     â”† fn   â”† 1       â”† 0.047619 â”‚\n",
       "â”‚ 0        â”† 1     â”† tn   â”† 2       â”† 0.064516 â”‚\n",
       "â”‚ 1        â”† 0     â”† fn   â”† 4       â”† 0.190476 â”‚\n",
       "â”‚ 1        â”† 0     â”† tn   â”† 11      â”† 0.354839 â”‚\n",
       "â”‚ 0        â”† 0     â”† fn   â”† 15      â”† 0.714286 â”‚\n",
       "â”‚ 0        â”† 0     â”† tn   â”† 18      â”† 0.580645 â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions.group_by(\"negative\", \"swear\", \"type\").len().with_columns((polars.col(\"len\") / polars.sum(\"len\").over(\"type\")).alias(\"perc\")).filter(col(\"type\").is_in([\"fn\", \"tn\"])).sort(\"len\").rename({\"len\": \"samples\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c684dfc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision:\t0.7500\n",
       "recall:\t\t0.3214\n",
       "fscore:\t\t0.4500\n",
       "accuracy:\t0.6333\n",
       "tn: 29\t fp: 3\n",
       "fn: 19\t tp: 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_swear = calculate_scores(predictions[\"label\"], predictions[\"pred_swear\"])\n",
    "scores_swear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74440dae",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "Check if text is about a female AND if it contains swear words, or if text is about a female AND it is negative. If so, predict the sample to be sexist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09b5fdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/tmp/ipykernel_243218/1595796645.py:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
       "  predictions = predictions.with_columns(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = predictions.with_columns(\n",
    "    polars.struct([\"pred_female_negative\", \"pred_swear\"]).map_elements(lambda x: x[\"pred_female_negative\"] and x[\"pred_swear\"]).alias(\"pred_ensemble\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6306348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision:\t0.8889\n",
       "recall:\t\t0.2857\n",
       "fscore:\t\t0.4324\n",
       "accuracy:\t0.6500\n",
       "tn: 31\t fp: 1\n",
       "fn: 20\t tp: 8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_ensemble = calculate_scores(predictions[\"label\"], predictions[\"pred_ensemble\"])\n",
    "scores_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a430f2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "529b5cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>precision</th><th>recall</th><th>fscore</th><th>accuracy</th><th>tp</th><th>tn</th><th>fp</th><th>fn</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;deberta&quot;</td><td>0.875</td><td>0.25</td><td>0.388889</td><td>0.633333</td><td>7</td><td>31</td><td>1</td><td>21</td></tr><tr><td>&quot;female&quot;</td><td>0.714286</td><td>0.714286</td><td>0.714286</td><td>0.733333</td><td>20</td><td>24</td><td>8</td><td>8</td></tr><tr><td>&quot;negative&quot;</td><td>0.5</td><td>0.428571</td><td>0.461538</td><td>0.533333</td><td>12</td><td>20</td><td>12</td><td>16</td></tr><tr><td>&quot;swear&quot;</td><td>0.75</td><td>0.321429</td><td>0.45</td><td>0.633333</td><td>9</td><td>29</td><td>3</td><td>19</td></tr><tr><td>&quot;female_negative&quot;</td><td>0.769231</td><td>0.357143</td><td>0.487805</td><td>0.65</td><td>10</td><td>29</td><td>3</td><td>18</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”\n",
       "â”‚ model           â”† precision â”† recall   â”† fscore   â”† â€¦ â”† tp  â”† tn  â”† fp  â”† fn  â”‚\n",
       "â”‚ ---             â”† ---       â”† ---      â”† ---      â”†   â”† --- â”† --- â”† --- â”† --- â”‚\n",
       "â”‚ str             â”† f64       â”† f64      â”† f64      â”†   â”† i64 â”† i64 â”† i64 â”† i64 â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•¡\n",
       "â”‚ deberta         â”† 0.875     â”† 0.25     â”† 0.388889 â”† â€¦ â”† 7   â”† 31  â”† 1   â”† 21  â”‚\n",
       "â”‚ female          â”† 0.714286  â”† 0.714286 â”† 0.714286 â”† â€¦ â”† 20  â”† 24  â”† 8   â”† 8   â”‚\n",
       "â”‚ negative        â”† 0.5       â”† 0.428571 â”† 0.461538 â”† â€¦ â”† 12  â”† 20  â”† 12  â”† 16  â”‚\n",
       "â”‚ swear           â”† 0.75      â”† 0.321429 â”† 0.45     â”† â€¦ â”† 9   â”† 29  â”† 3   â”† 19  â”‚\n",
       "â”‚ female_negative â”† 0.769231  â”† 0.357143 â”† 0.487805 â”† â€¦ â”† 10  â”† 29  â”† 3   â”† 18  â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_df = DataFrame([scores.asdict() for scores in [scores_deberta, scores_female, scores_negative, scores_swear, scores_female_negative, scores_ensemble]]).with_columns_seq(Series(name=\"model\", values=[\"deberta\", \"female\", \"negative\", \"swear\", \"female_negative\", \"ensemble\"])).select(\"model\", \"precision\", \"recall\", \"fscore\", \"accuracy\", \"tp\", \"tn\", \"fp\",\"fn\")\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e3f76",
   "metadata": {},
   "source": [
    "# Result storage\n",
    "We save all predictions in the `resource` directory in order to load them with \n",
    "the `ensemble_analysis.ipynb` notebook, where we do a more thorough analysis\n",
    "of the results and create some plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e034d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.write_csv(ROOT / \"resource\" / \"ensemble_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e36416df",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.write_csv(ROOT / \"resource\" / \"ensemble_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
