{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8acacc73",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c190a6e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "28995f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars\n",
    "from polars import DataFrame, col\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from label_legends.deberta import load_dataset, load_deberta, load_dataset\n",
    "from label_legends.preprocess import holdout, load_data, load_test, transform\n",
    "from label_legends.female import predict_female\n",
    "from label_legends.result import calculate_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77741141",
   "metadata": {},
   "source": [
    "# Use Deberta to create initial predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70fec1e3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/home/lukas/.local/share/uv/python/cpython-3.12.5-linux-x86_64-gnu/lib/python3.12/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
       "In addition, using fork() with Python in general is a recipe for mysterious\n",
       "deadlocks and crashes.\n",
       "\n",
       "The most likely reason you are seeing this error is because you are using the\n",
       "multiprocessing module on Linux, which uses fork() by default. This will be\n",
       "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
       "\n",
       "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
       "\n",
       "  self.pid = os.fork()\n",
       "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
       "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/lukas/.local/share/uv/python/cpython-3.12.5-linux-x86_64-gnu/lib/python3.12/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
       "In addition, using fork() with Python in general is a recipe for mysterious\n",
       "deadlocks and crashes.\n",
       "\n",
       "The most likely reason you are seeing this error is because you are using the\n",
       "multiprocessing module on Linux, which uses fork() by default. This will be\n",
       "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
       "\n",
       "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
       "\n",
       "  self.pid = os.fork()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/lukas/Programming/uni/nlp-ie-label-legends/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deberta = load_deberta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13f1c998",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/home/lukas/Programming/uni/nlp-ie-label-legends/src/label_legends/deberta.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
       "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/1470 : < :, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/lukas/Programming/uni/nlp-ie-label-legends/src/label_legends/deberta.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
       "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "üèÉ View run ./results at: https://mlflow.mahluke.page/#/experiments/0/runs/3d83c6467ac34c4698698edfd01c17fa\n",
       "üß™ View experiment at: https://mlflow.mahluke.page/#/experiments/0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_runtime': 730.5862,\n",
       " 'train_samples_per_second': 40.242,\n",
       " 'train_steps_per_second': 2.012,\n",
       " 'total_flos': 1405099900663200.0,\n",
       " 'train_loss': 0.4091674350556873,\n",
       " 'epoch': 1.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_out = deberta.train()\n",
    "train_out.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0851f2c6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/home/lukas/Programming/uni/nlp-ie-label-legends/src/label_legends/deberta.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
       "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  1/600 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.16233578, -0.09792556],\n",
       "       [ 1.48139   , -1.5975136 ],\n",
       "       [ 1.48139   , -1.5975136 ],\n",
       "       ...,\n",
       "       [ 0.22276703, -0.18155377],\n",
       "       [ 0.22276703, -0.18155377],\n",
       "       [ 0.22276703, -0.18155377]], dtype=float32), label_ids=array([1, 0, 0, ..., 1, 0, 1]), metrics={'test_loss': 0.3546888828277588, 'test_precision': 0.7497103128621089, 'test_recall': 0.6231139646869984, 'test_fscore': 0.6805750350631136, 'test_accuracy': 0.8481666666666666, 'test_tp': 1941, 'test_tn': 8237, 'test_fp': 648, 'test_fn': 1174, 'test_runtime': 77.6839, 'test_samples_per_second': 154.472, 'test_steps_per_second': 7.724})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = load_test().collect()\n",
    "test_transformed = transform(test)\n",
    "deberta_prediction = deberta.predict(load_dataset(test_transformed[\"text\"].to_list(), test_transformed[\"label\"].to_list()))\n",
    "deberta_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21b9bfc9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>label</th><th>deberta</th></tr><tr><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>100</td><td>1</td><td>0</td></tr><tr><td>10005</td><td>0</td><td>0</td></tr><tr><td>10006</td><td>0</td><td>0</td></tr><tr><td>10007</td><td>0</td><td>0</td></tr><tr><td>10008</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ id    ‚îÜ label ‚îÜ deberta ‚îÇ\n",
       "‚îÇ ---   ‚îÜ ---   ‚îÜ ---     ‚îÇ\n",
       "‚îÇ i64   ‚îÜ i64   ‚îÜ i64     ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ 100   ‚îÜ 1     ‚îÜ 0       ‚îÇ\n",
       "‚îÇ 10005 ‚îÜ 0     ‚îÜ 0       ‚îÇ\n",
       "‚îÇ 10006 ‚îÜ 0     ‚îÜ 0       ‚îÇ\n",
       "‚îÇ 10007 ‚îÜ 0     ‚îÜ 0       ‚îÇ\n",
       "‚îÇ 10008 ‚îÜ 0     ‚îÜ 0       ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = DataFrame({\"id\": test[\"id\"], \"label\": deberta_prediction.label_ids, \"deberta\": np.argmax(deberta_prediction.predictions, axis=1)})\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1e08b531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision:\t0.7497\n",
       "recall:\t\t0.6231\n",
       "fscore:\t\t0.6806\n",
       "accuracy:\t0.8482\n",
       "tn: 8237\t fp: 648\n",
       "fn: 1174\t tp: 1941"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_deberta = calculate_scores(predictions[\"label\"], predictions[\"deberta\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d35450d",
   "metadata": {},
   "source": [
    "# Post-Process negative predictions\n",
    "\n",
    "## Predict if sentence is referencing a female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4246bbf6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>type</th><th>label</th><th>deberta</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>100</td><td>&quot;fn&quot;</td><td>1</td><td>0</td></tr><tr><td>10005</td><td>&quot;tn&quot;</td><td>0</td><td>0</td></tr><tr><td>10006</td><td>&quot;tn&quot;</td><td>0</td><td>0</td></tr><tr><td>10007</td><td>&quot;tn&quot;</td><td>0</td><td>0</td></tr><tr><td>10008</td><td>&quot;tn&quot;</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ id    ‚îÜ type ‚îÜ label ‚îÜ deberta ‚îÇ\n",
       "‚îÇ ---   ‚îÜ ---  ‚îÜ ---   ‚îÜ ---     ‚îÇ\n",
       "‚îÇ i64   ‚îÜ str  ‚îÜ i64   ‚îÜ i64     ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ 100   ‚îÜ fn   ‚îÜ 1     ‚îÜ 0       ‚îÇ\n",
       "‚îÇ 10005 ‚îÜ tn   ‚îÜ 0     ‚îÜ 0       ‚îÇ\n",
       "‚îÇ 10006 ‚îÜ tn   ‚îÜ 0     ‚îÜ 0       ‚îÇ\n",
       "‚îÇ 10007 ‚îÜ tn   ‚îÜ 0     ‚îÜ 0       ‚îÇ\n",
       "‚îÇ 10008 ‚îÜ tn   ‚îÜ 0     ‚îÜ 0       ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def assign_type(prediction: int, label: str):\n",
    "    if prediction == 0:\n",
    "        if label == \"not sexist\":\n",
    "            return \"tn\"\n",
    "        return \"fn\"\n",
    "    if label == \"sexist\":\n",
    "        return \"tp\"\n",
    "    return \"fp\"\n",
    "\n",
    "\n",
    "predictions = predictions.join(test, on=\"id\").with_columns(polars.struct([\"deberta\", \"label_sexist\"]).map_elements(lambda x: assign_type(x['deberta'],x['label_sexist']), return_dtype=polars.String).alias(\"type\")).select([\"id\", \"type\", \"label\", \"deberta\"])\n",
    "\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6da64",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Add the predictions whether a text is about a female or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3504dec2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/tmp/ipykernel_75696/2309025452.py:8: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
       "  predictions = predictions.join(predict_female(test), on=\"id\").with_columns(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def alt_on_neg_pred(prediction: int, alternative: int):\n",
    "    \"\"\"Use the alternative if prediction is negative\"\"\"\n",
    "    if prediction == 1:\n",
    "        return 1\n",
    "    return alternative\n",
    "\n",
    "\n",
    "predictions = predictions.join(predict_female(test), on=\"id\").with_columns(\n",
    "    polars.struct([\"female\", \"deberta\"]).map_elements(lambda x: alt_on_neg_pred(x[\"deberta\"], x[\"female\"])).alias(\"pred_female\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104efdda",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We see that the prediction of most false positives is reconsidered, as those contain some female phrase. However, many of true negatives are also reconsidered, leading to a potentially worse precision. As we are focusing on increasing the recall, this is a trade-off we have to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c7f4ed6c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>female</th><th>type</th><th>samples</th><th>perc</th></tr><tr><td>i32</td><td>str</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>&quot;fp&quot;</td><td>575</td><td>0.887346</td></tr><tr><td>1</td><td>&quot;fn&quot;</td><td>1043</td><td>0.888416</td></tr><tr><td>1</td><td>&quot;tp&quot;</td><td>1657</td><td>0.853684</td></tr><tr><td>1</td><td>&quot;tn&quot;</td><td>5563</td><td>0.675367</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 4)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ female ‚îÜ type ‚îÜ samples ‚îÜ perc     ‚îÇ\n",
       "‚îÇ ---    ‚îÜ ---  ‚îÜ ---     ‚îÜ ---      ‚îÇ\n",
       "‚îÇ i32    ‚îÜ str  ‚îÜ u32     ‚îÜ f64      ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ 1      ‚îÜ fp   ‚îÜ 575     ‚îÜ 0.887346 ‚îÇ\n",
       "‚îÇ 1      ‚îÜ fn   ‚îÜ 1043    ‚îÜ 0.888416 ‚îÇ\n",
       "‚îÇ 1      ‚îÜ tp   ‚îÜ 1657    ‚îÜ 0.853684 ‚îÇ\n",
       "‚îÇ 1      ‚îÜ tn   ‚îÜ 5563    ‚îÜ 0.675367 ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions.group_by(\"female\", \"type\").len().with_columns((polars.col(\"len\") / polars.sum(\"len\").over(\"type\")).alias(\"perc\")).filter(col(\"female\")==1).sort(\"len\").rename({\"len\": \"samples\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd956d8",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4bcf56b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>type</th><th>label</th><th>deberta</th><th>female</th><th>pred_female</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i32</td><td>i64</td></tr></thead><tbody><tr><td>100</td><td>&quot;fn&quot;</td><td>1</td><td>0</td><td>1</td><td>1</td></tr><tr><td>10005</td><td>&quot;tn&quot;</td><td>0</td><td>0</td><td>1</td><td>1</td></tr><tr><td>10006</td><td>&quot;tn&quot;</td><td>0</td><td>0</td><td>1</td><td>1</td></tr><tr><td>10007</td><td>&quot;tn&quot;</td><td>0</td><td>0</td><td>1</td><td>1</td></tr><tr><td>10008</td><td>&quot;tn&quot;</td><td>0</td><td>0</td><td>1</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ id    ‚îÜ type ‚îÜ label ‚îÜ deberta ‚îÜ female ‚îÜ pred_female ‚îÇ\n",
       "‚îÇ ---   ‚îÜ ---  ‚îÜ ---   ‚îÜ ---     ‚îÜ ---    ‚îÜ ---         ‚îÇ\n",
       "‚îÇ i64   ‚îÜ str  ‚îÜ i64   ‚îÜ i64     ‚îÜ i32    ‚îÜ i64         ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ 100   ‚îÜ fn   ‚îÜ 1     ‚îÜ 0       ‚îÜ 1      ‚îÜ 1           ‚îÇ\n",
       "‚îÇ 10005 ‚îÜ tn   ‚îÜ 0     ‚îÜ 0       ‚îÜ 1      ‚îÜ 1           ‚îÇ\n",
       "‚îÇ 10006 ‚îÜ tn   ‚îÜ 0     ‚îÜ 0       ‚îÜ 1      ‚îÜ 1           ‚îÇ\n",
       "‚îÇ 10007 ‚îÜ tn   ‚îÜ 0     ‚îÜ 0       ‚îÜ 1      ‚îÜ 1           ‚îÇ\n",
       "‚îÇ 10008 ‚îÜ tn   ‚îÜ 0     ‚îÜ 0       ‚îÜ 1      ‚îÜ 1           ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4c6bb8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "If we would only use 'female' without some additional measurements, we would increase our recall considerably to over 95%, which comes at the cost of precision and f-score, which are drastically decreased. In order to not worsen the model that strongly overall, we add additional measurements to decide when to change a negative prediction by Deberta to a positive one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "43641401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision:\t0.3245\n",
       "recall:\t\t0.9579\n",
       "fscore:\t\t0.4848\n",
       "accuracy:\t0.4715\n",
       "tn: 2674\t fp: 6211\n",
       "fn: 131\t tp: 2984"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_female = calculate_scores(predictions[\"label\"], predictions[\"pred_female\"])\n",
    "scores_female"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5fe5d2",
   "metadata": {},
   "source": [
    "## Sentiment analysis\n",
    "Predict if text has a negative connotation. If true, and also targeted towards a female, predict the sample to be sexist.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5b385e",
   "metadata": {},
   "source": [
    "## Bad words\n",
    "Check if text contains a 'bad word', if so, predict the sample to be sexist."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
