{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_legends.preprocess import load_data, transform, majority, holdout_majority, load_test\n",
    "import polars as pl\n",
    "#deberta\n",
    "import numpy as np\n",
    "from polars import DataFrame, col\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from label_legends.deberta_majority import load_dataset, load_deberta, load_dataset\n",
    "from label_legends.deberta import load_dataset, load_deberta, load_dataset\n",
    "from label_legends.preprocess import holdout, load_data, load_test, transform\n",
    "from label_legends.female import predict_female\n",
    "from label_legends.result import calculate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/retipeter/Documents/TU Wien/NLP/nlp-ie-label-legends/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 6)\n",
      "┌───────┬────────────────────┬────────────────────┬────────────────────┬───────┬───────────────────┐\n",
      "│ id    ┆ text               ┆ tokens             ┆ token_ids          ┆ label ┆ rewire_id         │\n",
      "│ ---   ┆ ---                ┆ ---                ┆ ---                ┆ ---   ┆ ---               │\n",
      "│ i64   ┆ str                ┆ list[str]          ┆ list[i64]          ┆ i64   ┆ str               │\n",
      "╞═══════╪════════════════════╪════════════════════╪════════════════════╪═══════╪═══════════════════╡\n",
      "│ 0     ┆ I wonder what      ┆ [\"wonder\",         ┆ [2942, 2935, …     ┆ 1     ┆ sexism2022_englis │\n",
      "│       ┆ keeps that witc…   ┆ \"witch\", … \"😄\"]   ┆ 3000]              ┆       ┆ h-0               │\n",
      "│ 1     ┆ I wonder what      ┆ [\"wonder\",         ┆ [2942, 2935, …     ┆ 1     ┆ sexism2022_englis │\n",
      "│       ┆ keeps that witc…   ┆ \"witch\", … \"😄\"]   ┆ 3000]              ┆       ┆ h-0               │\n",
      "│ 10    ┆ Good for her! My   ┆ [\"good\", \"!\", …    ┆ [1181, 0, … 0]     ┆ 0     ┆ sexism2022_englis │\n",
      "│       ┆ grandson had …     ┆ \"!\"]               ┆                    ┆       ┆ h-100             │\n",
      "│ 1000  ┆ The article said   ┆ [\"article\", \"say\", ┆ [245, 2331, … 26]  ┆ 1     ┆ sexism2022_englis │\n",
      "│       ┆ Madonna offer…     ┆ … \".\"]             ┆                    ┆       ┆ h-10297           │\n",
      "│ 10000 ┆ Gasoline. The      ┆ [\"gasoline\", \".\",  ┆ [3000, 26, … 26]   ┆ 0     ┆ sexism2022_englis │\n",
      "│       ┆ answer 60% of Am…  ┆ … \".\"]             ┆                    ┆       ┆ h-12998           │\n",
      "└───────┴────────────────────┴────────────────────┴────────────────────┴───────┴───────────────────┘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_200, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>rewire_id_number</th><th>label_sum</th><th>text</th><th>tokens</th><th>token_ids</th><th>label</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>list[str]</td><td>list[i64]</td><td>i32</td></tr></thead><tbody><tr><td>17886</td><td>0</td><td>&quot;How do you make a Quija Board …</td><td>[&quot;make&quot;, &quot;quija&quot;, … &quot;.&quot;]</td><td>[1648, 3000, … 26]</td><td>0</td></tr><tr><td>7045</td><td>0</td><td>&quot;watch what women do not what t…</td><td>[&quot;watch&quot;, &quot;woman&quot;, &quot;say&quot;]</td><td>[2889, 2939, 2331]</td><td>0</td></tr><tr><td>18448</td><td>1</td><td>&quot;A certain Muppet female pig ha…</td><td>[&quot;certain&quot;, &quot;muppet&quot;, … &quot;#metoo&quot;]</td><td>[508, 3000, … 3000]</td><td>0</td></tr><tr><td>18749</td><td>0</td><td>&quot;Katy Perry and her connection …</td><td>[&quot;katy&quot;, &quot;perry&quot;, … &quot;.&quot;]</td><td>[3000, 3000, … 26]</td><td>0</td></tr><tr><td>15807</td><td>0</td><td>&quot; You got me! I&#x27;m really Soros&#x27;…</td><td>[&quot;!&quot;, &quot;really&quot;, … &quot;blmforcash&quot;]</td><td>[0, 2194, … 3000]</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>10674</td><td>0</td><td>&quot;Block/delete her from your pho…</td><td>[&quot;block&quot;, &quot;/&quot;, … &quot;.&quot;]</td><td>[376, 35, … 26]</td><td>0</td></tr><tr><td>9724</td><td>3</td><td>&quot;These are accomplished women o…</td><td>[&quot;accomplish&quot;, &quot;woman&quot;, … &quot;.&quot;]</td><td>[124, 2939, … 26]</td><td>1</td></tr><tr><td>8234</td><td>0</td><td>&quot;Word of The Hour catastrophe: …</td><td>[&quot;word&quot;, &quot;hour&quot;, … &quot;catástrofe&quot;]</td><td>[2945, 1318, … 3000]</td><td>0</td></tr><tr><td>2843</td><td>0</td><td>&quot;I&#x27;ll take your word for that. …</td><td>[&quot;word&quot;, &quot;.&quot;, … &quot;....&quot;]</td><td>[2945, 26, … 29]</td><td>0</td></tr><tr><td>2924</td><td>1</td><td>&quot;This woman is an idiot and was…</td><td>[&quot;woman&quot;, &quot;idiot&quot;, … &quot;.&quot;]</td><td>[2939, 1343, … 26]</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_200, 6)\n",
       "┌──────────────────┬───────────┬───────────────────┬───────────────────┬───────────────────┬───────┐\n",
       "│ rewire_id_number ┆ label_sum ┆ text              ┆ tokens            ┆ token_ids         ┆ label │\n",
       "│ ---              ┆ ---       ┆ ---               ┆ ---               ┆ ---               ┆ ---   │\n",
       "│ i64              ┆ i64       ┆ str               ┆ list[str]         ┆ list[i64]         ┆ i32   │\n",
       "╞══════════════════╪═══════════╪═══════════════════╪═══════════════════╪═══════════════════╪═══════╡\n",
       "│ 17886            ┆ 0         ┆ How do you make a ┆ [\"make\", \"quija\", ┆ [1648, 3000, …    ┆ 0     │\n",
       "│                  ┆           ┆ Quija Board …     ┆ … \".\"]            ┆ 26]               ┆       │\n",
       "│ 7045             ┆ 0         ┆ watch what women  ┆ [\"watch\",         ┆ [2889, 2939,      ┆ 0     │\n",
       "│                  ┆           ┆ do not what t…    ┆ \"woman\", \"say\"]   ┆ 2331]             ┆       │\n",
       "│ 18448            ┆ 1         ┆ A certain Muppet  ┆ [\"certain\",       ┆ [508, 3000, …     ┆ 0     │\n",
       "│                  ┆           ┆ female pig ha…    ┆ \"muppet\", …       ┆ 3000]             ┆       │\n",
       "│                  ┆           ┆                   ┆ \"#meto…           ┆                   ┆       │\n",
       "│ 18749            ┆ 0         ┆ Katy Perry and    ┆ [\"katy\", \"perry\", ┆ [3000, 3000, …    ┆ 0     │\n",
       "│                  ┆           ┆ her connection …  ┆ … \".\"]            ┆ 26]               ┆       │\n",
       "│ 15807            ┆ 0         ┆ You got me! I'm   ┆ [\"!\", \"really\", … ┆ [0, 2194, … 3000] ┆ 0     │\n",
       "│                  ┆           ┆ really Soros'…    ┆ \"blmforcash\"…     ┆                   ┆       │\n",
       "│ …                ┆ …         ┆ …                 ┆ …                 ┆ …                 ┆ …     │\n",
       "│ 10674            ┆ 0         ┆ Block/delete her  ┆ [\"block\", \"/\", …  ┆ [376, 35, … 26]   ┆ 0     │\n",
       "│                  ┆           ┆ from your pho…    ┆ \".\"]              ┆                   ┆       │\n",
       "│ 9724             ┆ 3         ┆ These are         ┆ [\"accomplish\",    ┆ [124, 2939, … 26] ┆ 1     │\n",
       "│                  ┆           ┆ accomplished      ┆ \"woman\", … \".\"]   ┆                   ┆       │\n",
       "│                  ┆           ┆ women o…          ┆                   ┆                   ┆       │\n",
       "│ 8234             ┆ 0         ┆ Word of The Hour  ┆ [\"word\", \"hour\",  ┆ [2945, 1318, …    ┆ 0     │\n",
       "│                  ┆           ┆ catastrophe: …    ┆ … \"catástrofe…    ┆ 3000]             ┆       │\n",
       "│ 2843             ┆ 0         ┆ I'll take your    ┆ [\"word\", \".\", …   ┆ [2945, 26, … 29]  ┆ 0     │\n",
       "│                  ┆           ┆ word for that. …  ┆ \"....\"]           ┆                   ┆       │\n",
       "│ 2924             ┆ 1         ┆ This woman is an  ┆ [\"woman\",         ┆ [2939, 1343, …    ┆ 0     │\n",
       "│                  ┆           ┆ idiot and was…    ┆ \"idiot\", … \".\"]   ┆ 26]               ┆       │\n",
       "└──────────────────┴───────────┴───────────────────┴───────────────────┴───────────────────┴───────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val, tra = holdout_majority()\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9_800, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>rewire_id_number</th><th>label_sum</th><th>text</th><th>tokens</th><th>token_ids</th><th>label</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>list[str]</td><td>list[i64]</td><td>i32</td></tr></thead><tbody><tr><td>8527</td><td>0</td><td>&quot;This is just perfect! I love t…</td><td>[&quot;just&quot;, &quot;perfect&quot;, … &quot;!&quot;]</td><td>[1483, 1967, … 0]</td><td>0</td></tr><tr><td>11951</td><td>1</td><td>&quot;She is good, at least she is n…</td><td>[&quot;good&quot;, &quot;,&quot;, … &quot;.&quot;]</td><td>[1181, 22, … 26]</td><td>0</td></tr><tr><td>14806</td><td>1</td><td>&quot;But of course, somehow the bla…</td><td>[&quot;course&quot;, &quot;,&quot;, … &quot;.&quot;]</td><td>[682, 22, … 26]</td><td>0</td></tr><tr><td>8817</td><td>0</td><td>&quot;Idk man, maybe you leave her s…</td><td>[&quot;idk&quot;, &quot;man&quot;, … &quot;reply&quot;]</td><td>[1345, 1652, … 2238]</td><td>0</td></tr><tr><td>17475</td><td>3</td><td>&quot;back again hi I am sammay I li…</td><td>[&quot;hi&quot;, &quot;sammay&quot;, … &quot;pest&quot;]</td><td>[1272, 3000, … 3000]</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>18316</td><td>2</td><td>&quot;Hard of hearing chicks are nic…</td><td>[&quot;hard&quot;, &quot;hearing&quot;, … &quot;.&quot;]</td><td>[1243, 3000, … 26]</td><td>1</td></tr><tr><td>6983</td><td>3</td><td>&quot;This actually makes me angry.I…</td><td>[&quot;actually&quot;, &quot;make&quot;, … &quot;case&quot;]</td><td>[143, 1648, … 493]</td><td>1</td></tr><tr><td>17348</td><td>3</td><td>&quot;the problem with this is that …</td><td>[&quot;problem&quot;, &quot;cuck&quot;, … &quot;?&quot;]</td><td>[2091, 712, … 98]</td><td>1</td></tr><tr><td>3666</td><td>3</td><td>&quot;This is bollocks! You can be w…</td><td>[&quot;bollock&quot;, &quot;!&quot;, … &quot;receive&quot;]</td><td>[3000, 0, … 2198]</td><td>1</td></tr><tr><td>19773</td><td>0</td><td>&quot;Look.....just because you have…</td><td>[&quot;look&quot;, &quot;.....&quot;, … &quot;.&quot;]</td><td>[1608, 30, … 26]</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9_800, 6)\n",
       "┌──────────────────┬───────────┬───────────────────┬───────────────────┬───────────────────┬───────┐\n",
       "│ rewire_id_number ┆ label_sum ┆ text              ┆ tokens            ┆ token_ids         ┆ label │\n",
       "│ ---              ┆ ---       ┆ ---               ┆ ---               ┆ ---               ┆ ---   │\n",
       "│ i64              ┆ i64       ┆ str               ┆ list[str]         ┆ list[i64]         ┆ i32   │\n",
       "╞══════════════════╪═══════════╪═══════════════════╪═══════════════════╪═══════════════════╪═══════╡\n",
       "│ 8527             ┆ 0         ┆ This is just      ┆ [\"just\",          ┆ [1483, 1967, … 0] ┆ 0     │\n",
       "│                  ┆           ┆ perfect! I love   ┆ \"perfect\", … \"!\"] ┆                   ┆       │\n",
       "│                  ┆           ┆ t…                ┆                   ┆                   ┆       │\n",
       "│ 11951            ┆ 1         ┆ She is good, at   ┆ [\"good\", \",\", …   ┆ [1181, 22, … 26]  ┆ 0     │\n",
       "│                  ┆           ┆ least she is n…   ┆ \".\"]              ┆                   ┆       │\n",
       "│ 14806            ┆ 1         ┆ But of course,    ┆ [\"course\", \",\", … ┆ [682, 22, … 26]   ┆ 0     │\n",
       "│                  ┆           ┆ somehow the bla…  ┆ \".\"]              ┆                   ┆       │\n",
       "│ 8817             ┆ 0         ┆ Idk man, maybe    ┆ [\"idk\", \"man\", …  ┆ [1345, 1652, …    ┆ 0     │\n",
       "│                  ┆           ┆ you leave her s…  ┆ \"reply\"]          ┆ 2238]             ┆       │\n",
       "│ 17475            ┆ 3         ┆ back again hi I   ┆ [\"hi\", \"sammay\",  ┆ [1272, 3000, …    ┆ 1     │\n",
       "│                  ┆           ┆ am sammay I li…   ┆ … \"pest\"]         ┆ 3000]             ┆       │\n",
       "│ …                ┆ …         ┆ …                 ┆ …                 ┆ …                 ┆ …     │\n",
       "│ 18316            ┆ 2         ┆ Hard of hearing   ┆ [\"hard\",          ┆ [1243, 3000, …    ┆ 1     │\n",
       "│                  ┆           ┆ chicks are nic…   ┆ \"hearing\", … \".\"] ┆ 26]               ┆       │\n",
       "│ 6983             ┆ 3         ┆ This actually     ┆ [\"actually\",      ┆ [143, 1648, …     ┆ 1     │\n",
       "│                  ┆           ┆ makes me angry.I… ┆ \"make\", … \"case\"] ┆ 493]              ┆       │\n",
       "│ 17348            ┆ 3         ┆ the problem with  ┆ [\"problem\",       ┆ [2091, 712, … 98] ┆ 1     │\n",
       "│                  ┆           ┆ this is that …    ┆ \"cuck\", … \"?\"]    ┆                   ┆       │\n",
       "│ 3666             ┆ 3         ┆ This is bollocks! ┆ [\"bollock\", \"!\",  ┆ [3000, 0, … 2198] ┆ 1     │\n",
       "│                  ┆           ┆ You can be w…     ┆ … \"receive\"]      ┆                   ┆       │\n",
       "│ 19773            ┆ 0         ┆ Look.....just     ┆ [\"look\", \".....\", ┆ [1608, 30, … 26]  ┆ 0     │\n",
       "│                  ┆           ┆ because you have… ┆ … \".\"]            ┆                   ┆       │\n",
       "└──────────────────┴───────────┴───────────────────┴───────────────────┴───────────────────┴───────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deberta running on majority here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "deberta = load_deberta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3065 [00:00<?, ?it/s]/Users/retipeter/Documents/TU Wien/NLP/nlp-ie-label-legends/src/label_legends/deberta_majority.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "  3%|▎         | 100/3065 [00:58<30:21,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5901, 'grad_norm': 0.8738930821418762, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 200/3065 [01:55<27:07,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5517, 'grad_norm': 2.5674209594726562, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 300/3065 [02:51<25:58,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4724, 'grad_norm': 5.353095531463623, 'learning_rate': 1.9644760213143874e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 400/3065 [03:49<25:36,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3738, 'grad_norm': 4.014645099639893, 'learning_rate': 1.8934280639431617e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 500/3065 [04:46<24:29,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3817, 'grad_norm': 4.943447113037109, 'learning_rate': 1.822380106571936e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 600/3065 [05:44<23:32,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3499, 'grad_norm': 1.85252845287323, 'learning_rate': 1.751332149200711e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 20%|██        | 613/3065 [06:36<25:46,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31990790367126465, 'eval_precision': 0.779601406799531, 'eval_recall': 0.646887159533074, 'eval_fscore': 0.7070707070707071, 'eval_accuracy': 0.8688095238095238, 'eval_tp': 665, 'eval_tn': 2984, 'eval_fp': 188, 'eval_fn': 363, 'eval_runtime': 45.1225, 'eval_samples_per_second': 93.08, 'eval_steps_per_second': 5.829, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/retipeter/Documents/TU Wien/NLP/nlp-ie-label-legends/src/label_legends/deberta_majority.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 23%|██▎       | 700/3065 [07:29<22:45,  1.73it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3231, 'grad_norm': 1.4562348127365112, 'learning_rate': 1.680284191829485e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 800/3065 [08:26<21:50,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2993, 'grad_norm': 2.7944037914276123, 'learning_rate': 1.6092362344582596e-05, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 900/3065 [09:24<20:40,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2803, 'grad_norm': 3.1831862926483154, 'learning_rate': 1.5381882770870337e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1000/3065 [10:22<19:43,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2828, 'grad_norm': 10.380820274353027, 'learning_rate': 1.4671403197158082e-05, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1100/3065 [11:19<18:51,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2972, 'grad_norm': 12.751142501831055, 'learning_rate': 1.3960923623445828e-05, 'epoch': 1.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1200/3065 [12:16<18:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3006, 'grad_norm': 3.834257125854492, 'learning_rate': 1.3250444049733571e-05, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 40%|████      | 1226/3065 [13:17<16:25,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34876400232315063, 'eval_precision': 0.7070524412296564, 'eval_recall': 0.7607003891050583, 'eval_fscore': 0.7328959700093721, 'eval_accuracy': 0.8642857142857143, 'eval_tp': 782, 'eval_tn': 2848, 'eval_fp': 324, 'eval_fn': 246, 'eval_runtime': 45.4507, 'eval_samples_per_second': 92.408, 'eval_steps_per_second': 5.786, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/retipeter/Documents/TU Wien/NLP/nlp-ie-label-legends/src/label_legends/deberta_majority.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 42%|████▏     | 1300/3065 [14:02<16:45,  1.76it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2079, 'grad_norm': 12.443868637084961, 'learning_rate': 1.2539964476021315e-05, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 1400/3065 [14:59<15:55,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2114, 'grad_norm': 3.08478045463562, 'learning_rate': 1.1829484902309059e-05, 'epoch': 2.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1500/3065 [15:57<15:03,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1975, 'grad_norm': 6.4972758293151855, 'learning_rate': 1.1119005328596803e-05, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1600/3065 [16:54<14:06,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1956, 'grad_norm': 6.872176170349121, 'learning_rate': 1.0408525754884548e-05, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1700/3065 [17:51<13:04,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1776, 'grad_norm': 20.328386306762695, 'learning_rate': 9.698046181172292e-06, 'epoch': 2.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1800/3065 [18:48<11:56,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1975, 'grad_norm': 10.59494400024414, 'learning_rate': 8.987566607460036e-06, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 60%|██████    | 1839/3065 [19:56<11:10,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45301249623298645, 'eval_precision': 0.7348119575699132, 'eval_recall': 0.7412451361867705, 'eval_fscore': 0.7380145278450363, 'eval_accuracy': 0.8711904761904762, 'eval_tp': 762, 'eval_tn': 2897, 'eval_fp': 275, 'eval_fn': 266, 'eval_runtime': 44.9441, 'eval_samples_per_second': 93.45, 'eval_steps_per_second': 5.852, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/retipeter/Documents/TU Wien/NLP/nlp-ie-label-legends/src/label_legends/deberta_majority.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 62%|██████▏   | 1900/3065 [20:33<11:00,  1.76it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1531, 'grad_norm': 10.173916816711426, 'learning_rate': 8.27708703374778e-06, 'epoch': 3.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 2000/3065 [21:30<10:10,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1471, 'grad_norm': 6.339789867401123, 'learning_rate': 7.566607460035525e-06, 'epoch': 3.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 2100/3065 [22:27<09:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1082, 'grad_norm': 0.07047244906425476, 'learning_rate': 6.8561278863232685e-06, 'epoch': 3.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 2200/3065 [23:24<08:09,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1362, 'grad_norm': 0.5132527351379395, 'learning_rate': 6.145648312611013e-06, 'epoch': 3.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 2300/3065 [24:21<07:30,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1175, 'grad_norm': 0.686800479888916, 'learning_rate': 5.435168738898757e-06, 'epoch': 3.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2400/3065 [25:19<06:19,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1266, 'grad_norm': 9.269302368164062, 'learning_rate': 4.724689165186501e-06, 'epoch': 3.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 80%|████████  | 2452/3065 [26:33<05:20,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5708104372024536, 'eval_precision': 0.7416413373860182, 'eval_recall': 0.7120622568093385, 'eval_fscore': 0.7265508684863523, 'eval_accuracy': 0.8688095238095238, 'eval_tp': 732, 'eval_tn': 2917, 'eval_fp': 255, 'eval_fn': 296, 'eval_runtime': 45.1898, 'eval_samples_per_second': 92.941, 'eval_steps_per_second': 5.82, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/retipeter/Documents/TU Wien/NLP/nlp-ie-label-legends/src/label_legends/deberta_majority.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 82%|████████▏ | 2500/3065 [27:03<05:22,  1.75it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1053, 'grad_norm': 0.9246652126312256, 'learning_rate': 4.0142095914742455e-06, 'epoch': 4.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 2600/3065 [28:00<04:25,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0718, 'grad_norm': 0.13763460516929626, 'learning_rate': 3.3037300177619897e-06, 'epoch': 4.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2700/3065 [28:58<03:27,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0744, 'grad_norm': 0.2980663776397705, 'learning_rate': 2.5932504440497336e-06, 'epoch': 4.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 2800/3065 [29:55<02:30,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1005, 'grad_norm': 28.969125747680664, 'learning_rate': 1.882770870337478e-06, 'epoch': 4.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 2900/3065 [30:52<01:33,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0785, 'grad_norm': 2.0508663654327393, 'learning_rate': 1.172291296625222e-06, 'epoch': 4.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 3000/3065 [31:49<00:37,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0903, 'grad_norm': 0.09931075572967529, 'learning_rate': 4.618117229129663e-07, 'epoch': 4.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3065/3065 [32:26<00:00,  1.88it/s]/Users/retipeter/Documents/TU Wien/NLP/nlp-ie-label-legends/src/label_legends/deberta_majority.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      "100%|██████████| 3065/3065 [33:13<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6569569110870361, 'eval_precision': 0.7240038872691934, 'eval_recall': 0.7247081712062257, 'eval_fscore': 0.7243558580456976, 'eval_accuracy': 0.865, 'eval_tp': 745, 'eval_tn': 2888, 'eval_fp': 284, 'eval_fn': 283, 'eval_runtime': 45.3808, 'eval_samples_per_second': 92.55, 'eval_steps_per_second': 5.795, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3065/3065 [33:17<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1997.2714, 'train_samples_per_second': 24.533, 'train_steps_per_second': 1.535, 'train_loss': 0.23006841447963994, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3065/3065 [33:18<00:00,  1.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_runtime': 1997.2714,\n",
       " 'train_samples_per_second': 24.533,\n",
       " 'train_steps_per_second': 1.535,\n",
       " 'total_flos': 2241109160556000.0,\n",
       " 'train_loss': 0.23006841447963994,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_out = deberta.train()\n",
    "train_out.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/retipeter/Documents/TU Wien/NLP/nlp-ie-label-legends/src/label_legends/deberta_majority.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|██████████| 750/750 [02:05<00:00,  5.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.02157354, -0.15974028],\n",
       "       [ 0.16012895, -0.31555876],\n",
       "       [ 0.16012895, -0.31555876],\n",
       "       ...,\n",
       "       [-0.03087621, -0.13163614],\n",
       "       [-0.03087621, -0.13163614],\n",
       "       [-0.03087621, -0.13163614]], dtype=float32), label_ids=array([1, 0, 0, ..., 1, 0, 1]), metrics={'test_loss': 0.38887882232666016, 'test_precision': 0.7482574825748257, 'test_recall': 0.5858747993579454, 'test_fscore': 0.6571840115232265, 'test_accuracy': 0.8413333333333334, 'test_tp': 1825, 'test_tn': 8271, 'test_fp': 614, 'test_fn': 1290, 'test_runtime': 126.3444, 'test_samples_per_second': 94.978, 'test_steps_per_second': 5.936})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = load_test().collect()\n",
    "test_transformed = transform(test)\n",
    "deberta_prediction = deberta.predict(load_dataset(test_transformed[\"text\"].to_list(), test_transformed[\"label\"].to_list()))\n",
    "deberta_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>label</th><th>deberta</th></tr><tr><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>100</td><td>1</td><td>0</td></tr><tr><td>10005</td><td>0</td><td>0</td></tr><tr><td>10006</td><td>0</td><td>0</td></tr><tr><td>10007</td><td>0</td><td>0</td></tr><tr><td>10008</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌───────┬───────┬─────────┐\n",
       "│ id    ┆ label ┆ deberta │\n",
       "│ ---   ┆ ---   ┆ ---     │\n",
       "│ i64   ┆ i64   ┆ i64     │\n",
       "╞═══════╪═══════╪═════════╡\n",
       "│ 100   ┆ 1     ┆ 0       │\n",
       "│ 10005 ┆ 0     ┆ 0       │\n",
       "│ 10006 ┆ 0     ┆ 0       │\n",
       "│ 10007 ┆ 0     ┆ 0       │\n",
       "│ 10008 ┆ 0     ┆ 0       │\n",
       "└───────┴───────┴─────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = DataFrame({\"id\": test[\"id\"], \"label\": deberta_prediction.label_ids, \"deberta\": np.argmax(deberta_prediction.predictions, axis=1)})\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision:\t0.7483\n",
       "recall:\t\t0.5859\n",
       "fscore:\t\t0.6572\n",
       "accuracy:\t0.8413\n",
       "tn: 8271\t fp: 614\n",
       "fn: 1290\t tp: 1825"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_deberta = calculate_scores(predictions[\"label\"], predictions[\"deberta\"])\n",
    "scores_deberta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
