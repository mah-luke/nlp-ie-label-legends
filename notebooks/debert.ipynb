{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for DeBERTa-v3-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import TokenList\n",
    "import polars as pl\n",
    "from stanza.models.common.doc import Token\n",
    "from label_legends.preprocess import create_conllu, holdout, load_conllu, load_data, load_train, transform, load_vectorizer, reverse_vocabulary, vocabulary, ids_to_tokens, tokens_to_ids, vectorize_tokens, strip_stopwords\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dependencies for this specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoConfig, DebertaV2Tokenizer, Trainer, TrainingArguments\n",
    "MODEL_NAME = 'microsoft/deberta-v3-base'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "tokenizer =DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "#DO I need the tokenizer here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (60_000, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>rewire_id</th><th>text</th><th>annotator</th><th>label_sexist</th><th>label_category</th><th>label_vector</th><th>split</th><th>tokens</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>0</td><td>&quot;sexism2022_english-0&quot;</td><td>&quot; I wonder what keeps that witcâ€¦</td><td>17</td><td>&quot;sexist&quot;</td><td>&quot;2. derogation&quot;</td><td>&quot;2.2 aggressive and emotive attâ€¦</td><td>&quot;train&quot;</td><td>[&quot;i&quot;, &quot;wonder&quot;, â€¦ &quot;ğŸ˜„&quot;]</td></tr><tr><td>1</td><td>&quot;sexism2022_english-0&quot;</td><td>&quot; I wonder what keeps that witcâ€¦</td><td>2</td><td>&quot;sexist&quot;</td><td>&quot;2. derogation&quot;</td><td>&quot;2.2 aggressive and emotive attâ€¦</td><td>&quot;train&quot;</td><td>[&quot;i&quot;, &quot;wonder&quot;, â€¦ &quot;ğŸ˜„&quot;]</td></tr><tr><td>10</td><td>&quot;sexism2022_english-100&quot;</td><td>&quot;Good for her! My grandson had â€¦</td><td>3</td><td>&quot;not sexist&quot;</td><td>&quot;none&quot;</td><td>&quot;none&quot;</td><td>&quot;train&quot;</td><td>[&quot;good&quot;, &quot;for&quot;, â€¦ &quot;!&quot;]</td></tr><tr><td>100</td><td>&quot;sexism2022_english-10026&quot;</td><td>&quot;It is not insulting, it&#x27;s **exâ€¦</td><td>14</td><td>&quot;sexist&quot;</td><td>&quot;2. derogation&quot;</td><td>&quot;2.1 descriptive attacks&quot;</td><td>&quot;test&quot;</td><td>[&quot;it&quot;, &quot;be&quot;, â€¦ &quot;.**&quot;]</td></tr><tr><td>1000</td><td>&quot;sexism2022_english-10297&quot;</td><td>&quot;The article said Madonna offerâ€¦</td><td>5</td><td>&quot;sexist&quot;</td><td>&quot;2. derogation&quot;</td><td>&quot;2.3 dehumanising attacks &amp; oveâ€¦</td><td>&quot;train&quot;</td><td>[&quot;the&quot;, &quot;article&quot;, â€¦ &quot;.&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>9995</td><td>&quot;sexism2022_english-12996&quot;</td><td>&quot;Shudder.. if you had to have sâ€¦</td><td>17</td><td>&quot;sexist&quot;</td><td>&quot;2. derogation&quot;</td><td>&quot;2.3 dehumanising attacks &amp; oveâ€¦</td><td>&quot;test&quot;</td><td>[&quot;shudder&quot;, &quot;..&quot;, â€¦ &quot;.&quot;]</td></tr><tr><td>9996</td><td>&quot;sexism2022_english-12997&quot;</td><td>&quot;You mean one that forces womenâ€¦</td><td>6</td><td>&quot;not sexist&quot;</td><td>&quot;none&quot;</td><td>&quot;none&quot;</td><td>&quot;train&quot;</td><td>[&quot;you&quot;, &quot;mean&quot;, â€¦ &quot;?&quot;]</td></tr><tr><td>9997</td><td>&quot;sexism2022_english-12997&quot;</td><td>&quot;You mean one that forces womenâ€¦</td><td>4</td><td>&quot;not sexist&quot;</td><td>&quot;none&quot;</td><td>&quot;none&quot;</td><td>&quot;train&quot;</td><td>[&quot;you&quot;, &quot;mean&quot;, â€¦ &quot;?&quot;]</td></tr><tr><td>9998</td><td>&quot;sexism2022_english-12997&quot;</td><td>&quot;You mean one that forces womenâ€¦</td><td>2</td><td>&quot;sexist&quot;</td><td>&quot;3. animosity&quot;</td><td>&quot;3.2 immutable gender differencâ€¦</td><td>&quot;train&quot;</td><td>[&quot;you&quot;, &quot;mean&quot;, â€¦ &quot;?&quot;]</td></tr><tr><td>9999</td><td>&quot;sexism2022_english-12998&quot;</td><td>&quot;Gasoline. The answer 60% of Amâ€¦</td><td>9</td><td>&quot;sexist&quot;</td><td>&quot;1. threats, plans to harm and â€¦</td><td>&quot;1.1 threats of harm&quot;</td><td>&quot;train&quot;</td><td>[&quot;gasoline&quot;, &quot;.&quot;, â€¦ &quot;.&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (60_000, 9)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ id   â”† rewire_id   â”† text        â”† annotator â”† â€¦ â”† label_categ â”† label_vect â”† split â”† tokens     â”‚\n",
       "â”‚ ---  â”† ---         â”† ---         â”† ---       â”†   â”† ory         â”† or         â”† ---   â”† ---        â”‚\n",
       "â”‚ i64  â”† str         â”† str         â”† i64       â”†   â”† ---         â”† ---        â”† str   â”† list[str]  â”‚\n",
       "â”‚      â”†             â”†             â”†           â”†   â”† str         â”† str        â”†       â”†            â”‚\n",
       "â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0    â”† sexism2022_ â”† I wonder    â”† 17        â”† â€¦ â”† 2.          â”† 2.2        â”† train â”† [\"i\",      â”‚\n",
       "â”‚      â”† english-0   â”† what keeps  â”†           â”†   â”† derogation  â”† aggressive â”†       â”† \"wonder\",  â”‚\n",
       "â”‚      â”†             â”† that witcâ€¦  â”†           â”†   â”†             â”† and        â”†       â”† â€¦ \"ğŸ˜„\"]    â”‚\n",
       "â”‚      â”†             â”†             â”†           â”†   â”†             â”† emotive    â”†       â”†            â”‚\n",
       "â”‚      â”†             â”†             â”†           â”†   â”†             â”† attâ€¦       â”†       â”†            â”‚\n",
       "â”‚ 1    â”† sexism2022_ â”† I wonder    â”† 2         â”† â€¦ â”† 2.          â”† 2.2        â”† train â”† [\"i\",      â”‚\n",
       "â”‚      â”† english-0   â”† what keeps  â”†           â”†   â”† derogation  â”† aggressive â”†       â”† \"wonder\",  â”‚\n",
       "â”‚      â”†             â”† that witcâ€¦  â”†           â”†   â”†             â”† and        â”†       â”† â€¦ \"ğŸ˜„\"]    â”‚\n",
       "â”‚      â”†             â”†             â”†           â”†   â”†             â”† emotive    â”†       â”†            â”‚\n",
       "â”‚      â”†             â”†             â”†           â”†   â”†             â”† attâ€¦       â”†       â”†            â”‚\n",
       "â”‚ 10   â”† sexism2022_ â”† Good for    â”† 3         â”† â€¦ â”† none        â”† none       â”† train â”† [\"good\",   â”‚\n",
       "â”‚      â”† english-100 â”† her! My     â”†           â”†   â”†             â”†            â”†       â”† \"for\", â€¦   â”‚\n",
       "â”‚      â”†             â”† grandson    â”†           â”†   â”†             â”†            â”†       â”† \"!\"]       â”‚\n",
       "â”‚      â”†             â”† had â€¦       â”†           â”†   â”†             â”†            â”†       â”†            â”‚\n",
       "â”‚ 100  â”† sexism2022_ â”† It is not   â”† 14        â”† â€¦ â”† 2.          â”† 2.1 descri â”† test  â”† [\"it\",     â”‚\n",
       "â”‚      â”† english-100 â”† insulting,  â”†           â”†   â”† derogation  â”† ptive      â”†       â”† \"be\", â€¦    â”‚\n",
       "â”‚      â”† 26          â”† it's **exâ€¦  â”†           â”†   â”†             â”† attacks    â”†       â”† \".**\"]     â”‚\n",
       "â”‚ 1000 â”† sexism2022_ â”† The article â”† 5         â”† â€¦ â”† 2.          â”† 2.3 dehuma â”† train â”† [\"the\",    â”‚\n",
       "â”‚      â”† english-102 â”† said        â”†           â”†   â”† derogation  â”† nising     â”†       â”† \"article\", â”‚\n",
       "â”‚      â”† 97          â”† Madonna     â”†           â”†   â”†             â”† attacks &  â”†       â”† â€¦ \".\"]     â”‚\n",
       "â”‚      â”†             â”† offerâ€¦      â”†           â”†   â”†             â”† oveâ€¦       â”†       â”†            â”‚\n",
       "â”‚ â€¦    â”† â€¦           â”† â€¦           â”† â€¦         â”† â€¦ â”† â€¦           â”† â€¦          â”† â€¦     â”† â€¦          â”‚\n",
       "â”‚ 9995 â”† sexism2022_ â”† Shudder..   â”† 17        â”† â€¦ â”† 2.          â”† 2.3 dehuma â”† test  â”† [\"shudder\" â”‚\n",
       "â”‚      â”† english-129 â”† if you had  â”†           â”†   â”† derogation  â”† nising     â”†       â”† , \"..\", â€¦  â”‚\n",
       "â”‚      â”† 96          â”† to have sâ€¦  â”†           â”†   â”†             â”† attacks &  â”†       â”† \".\"]       â”‚\n",
       "â”‚      â”†             â”†             â”†           â”†   â”†             â”† oveâ€¦       â”†       â”†            â”‚\n",
       "â”‚ 9996 â”† sexism2022_ â”† You mean    â”† 6         â”† â€¦ â”† none        â”† none       â”† train â”† [\"you\",    â”‚\n",
       "â”‚      â”† english-129 â”† one that    â”†           â”†   â”†             â”†            â”†       â”† \"mean\", â€¦  â”‚\n",
       "â”‚      â”† 97          â”† forces      â”†           â”†   â”†             â”†            â”†       â”† \"?\"]       â”‚\n",
       "â”‚      â”†             â”† womenâ€¦      â”†           â”†   â”†             â”†            â”†       â”†            â”‚\n",
       "â”‚ 9997 â”† sexism2022_ â”† You mean    â”† 4         â”† â€¦ â”† none        â”† none       â”† train â”† [\"you\",    â”‚\n",
       "â”‚      â”† english-129 â”† one that    â”†           â”†   â”†             â”†            â”†       â”† \"mean\", â€¦  â”‚\n",
       "â”‚      â”† 97          â”† forces      â”†           â”†   â”†             â”†            â”†       â”† \"?\"]       â”‚\n",
       "â”‚      â”†             â”† womenâ€¦      â”†           â”†   â”†             â”†            â”†       â”†            â”‚\n",
       "â”‚ 9998 â”† sexism2022_ â”† You mean    â”† 2         â”† â€¦ â”† 3.          â”† 3.2        â”† train â”† [\"you\",    â”‚\n",
       "â”‚      â”† english-129 â”† one that    â”†           â”†   â”† animosity   â”† immutable  â”†       â”† \"mean\", â€¦  â”‚\n",
       "â”‚      â”† 97          â”† forces      â”†           â”†   â”†             â”† gender     â”†       â”† \"?\"]       â”‚\n",
       "â”‚      â”†             â”† womenâ€¦      â”†           â”†   â”†             â”† differencâ€¦ â”†       â”†            â”‚\n",
       "â”‚ 9999 â”† sexism2022_ â”† Gasoline.   â”† 9         â”† â€¦ â”† 1. threats, â”† 1.1        â”† train â”† [\"gasoline â”‚\n",
       "â”‚      â”† english-129 â”† The answer  â”†           â”†   â”† plans to    â”† threats of â”†       â”† \", \".\", â€¦  â”‚\n",
       "â”‚      â”† 98          â”† 60% of Amâ€¦  â”†           â”†   â”† harm and â€¦  â”† harm       â”†       â”† \".\"]       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, tra = holdout()\n",
    "tra = transform(tra)\n",
    "val = transform(val)\n",
    "\n",
    "# Convert 'label' column from string '0' and '1' to integer 0 and 1\n",
    "tra = tra.with_columns(\n",
    "    polars.col(\"label\").cast(polars.Int32)\n",
    ")\n",
    "val = val.with_columns(\n",
    "    polars.col(\"label\").cast(polars.Int32)\n",
    ")\n",
    "\n",
    "train_texts = tra[\"text\"].to_list()\n",
    "train_labels = tra[\"label\"].to_list()\n",
    "val_texts = val[\"text\"].to_list()\n",
    "val_labels = val[\"label\"].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 3675/11025 [15:43:17<31:26:34, 15.40s/it]\n",
      "\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "train_encodings = tokenizer(\n",
    "    train_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,  # Adjust this as needed\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    val_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SexistDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    \n",
    "    \n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"micro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SexistDataset(train_encodings, train_labels)\n",
    "val_dataset = SexistDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/retipeter/Documents/TU Wien/NLP/nlp-ie-label-legends/.venv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/b6/1mflrv1s5s9b5pj5n4cg2hjw0000gn/T/ipykernel_88913/1078182425.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "  1%|          | 119/11025 [12:16:45<1125:22:25, 371.48s/it]\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"epoch\",  # Keep this for evaluation at the end of each epoch\n",
    "    logging_steps=100,  # Log less frequently than every step, but more often than every epoch\n",
    "    save_strategy=\"epoch\",  # Save checkpoints at the end of each epoch\n",
    "    load_best_model_at_end=True,  # Load best model based on evaluation loss\n",
    "    metric_for_best_model='eval_loss',  # Track evaluation loss for best model\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "#trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11025 [00:00<?, ?it/s]/var/folders/b6/1mflrv1s5s9b5pj5n4cg2hjw0000gn/T/ipykernel_88913/2940528382.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "  1%|          | 100/11025 [00:36<1:06:37,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5642, 'grad_norm': 2.3384995460510254, 'learning_rate': 1.981859410430839e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 200/11025 [01:13<1:06:03,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5272, 'grad_norm': 15.648771286010742, 'learning_rate': 1.963718820861678e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–         | 300/11025 [01:49<1:05:22,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5822, 'grad_norm': 1.468311071395874, 'learning_rate': 1.945578231292517e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 400/11025 [02:26<1:04:53,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5128, 'grad_norm': 1.9529191255569458, 'learning_rate': 1.9274376417233563e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–         | 500/11025 [03:03<1:04:26,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4616, 'grad_norm': 3.1888108253479004, 'learning_rate': 1.9092970521541953e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 600/11025 [03:39<1:03:42,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4432, 'grad_norm': 12.392617225646973, 'learning_rate': 1.8911564625850343e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 700/11025 [04:16<1:03:10,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.453, 'grad_norm': 2.466106414794922, 'learning_rate': 1.8730158730158732e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 800/11025 [04:53<1:02:33,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4374, 'grad_norm': 11.236799240112305, 'learning_rate': 1.8548752834467122e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 900/11025 [05:30<1:01:58,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.436, 'grad_norm': 6.2112321853637695, 'learning_rate': 1.836734693877551e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 1000/11025 [06:06<1:01:17,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4448, 'grad_norm': 10.407325744628906, 'learning_rate': 1.81859410430839e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–‰         | 1100/11025 [06:43<1:00:38,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4364, 'grad_norm': 3.7003865242004395, 'learning_rate': 1.8004535147392294e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 1200/11025 [07:20<1:00:05,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3919, 'grad_norm': 1.5171334743499756, 'learning_rate': 1.782312925170068e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 1300/11025 [07:56<1:00:10,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.434, 'grad_norm': 8.173460960388184, 'learning_rate': 1.7641723356009073e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–        | 1400/11025 [08:33<58:49,  2.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4301, 'grad_norm': 3.084192991256714, 'learning_rate': 1.7460317460317463e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 1500/11025 [09:10<58:15,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4271, 'grad_norm': 4.467639923095703, 'learning_rate': 1.7278911564625852e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–        | 1600/11025 [09:46<57:39,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4014, 'grad_norm': 4.073261260986328, 'learning_rate': 1.7097505668934242e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 1700/11025 [19:27<3:49:59,  1.48s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4436, 'grad_norm': 5.532982349395752, 'learning_rate': 1.691609977324263e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–‹        | 1800/11025 [20:04<56:55,  2.70it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4133, 'grad_norm': 4.643570423126221, 'learning_rate': 1.673469387755102e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 1900/11025 [20:41<55:35,  2.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.385, 'grad_norm': 2.6342008113861084, 'learning_rate': 1.655328798185941e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 2000/11025 [21:18<55:01,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4044, 'grad_norm': 13.557908058166504, 'learning_rate': 1.63718820861678e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 2100/11025 [21:56<54:47,  2.72it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3847, 'grad_norm': 4.300295352935791, 'learning_rate': 1.6190476190476193e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–‰        | 2200/11025 [22:32<54:23,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4002, 'grad_norm': 3.9787437915802, 'learning_rate': 1.6009070294784583e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆ        | 2300/11025 [23:09<53:35,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4527, 'grad_norm': 8.525747299194336, 'learning_rate': 1.5827664399092972e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 2400/11025 [23:46<53:06,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.435, 'grad_norm': 8.526215553283691, 'learning_rate': 1.5646258503401362e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–       | 2500/11025 [24:23<52:22,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3802, 'grad_norm': 28.95743751525879, 'learning_rate': 1.546485260770975e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 2600/11025 [25:00<51:44,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4411, 'grad_norm': 7.04342794418335, 'learning_rate': 1.528344671201814e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 2700/11025 [25:37<51:14,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3894, 'grad_norm': 6.365671157836914, 'learning_rate': 1.510204081632653e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 2800/11025 [26:14<50:30,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4057, 'grad_norm': 3.6063196659088135, 'learning_rate': 1.4920634920634922e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–‹       | 2900/11025 [26:51<50:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.405, 'grad_norm': 4.066201210021973, 'learning_rate': 1.4739229024943311e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 3000/11025 [27:28<49:15,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3891, 'grad_norm': 2.5872621536254883, 'learning_rate': 1.4557823129251703e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 3100/11025 [28:05<48:49,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3744, 'grad_norm': 1.2128922939300537, 'learning_rate': 1.4376417233560092e-05, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 3200/11025 [28:42<48:09,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3647, 'grad_norm': 3.478449821472168, 'learning_rate': 1.4195011337868484e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–‰       | 3300/11025 [29:19<47:48,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3944, 'grad_norm': 4.648478984832764, 'learning_rate': 1.4013605442176872e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 3400/11025 [29:56<46:52,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4202, 'grad_norm': 2.7207529544830322, 'learning_rate': 1.3832199546485261e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 3500/11025 [30:33<46:13,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3414, 'grad_norm': 0.6616837978363037, 'learning_rate': 1.3650793650793652e-05, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 3600/11025 [31:09<45:40,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4137, 'grad_norm': 8.376431465148926, 'learning_rate': 1.3469387755102042e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 3675/11025 [31:37<45:16,  2.71it/s]\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 3675/11025 [34:02<45:16,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34722602367401123, 'eval_accuracy': 0.8602380952380952, 'eval_f1': 0.8602380952380952, 'eval_precision': 0.8602380952380952, 'eval_recall': 0.8602380952380952, 'eval_runtime': 145.2868, 'eval_samples_per_second': 86.725, 'eval_steps_per_second': 10.841, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b6/1mflrv1s5s9b5pj5n4cg2hjw0000gn/T/ipykernel_88913/2940528382.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 3700/11025 [34:14<46:07,  2.65it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4049, 'grad_norm': 1.6981748342514038, 'learning_rate': 1.3287981859410433e-05, 'epoch': 1.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 3800/11025 [34:51<44:27,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3576, 'grad_norm': 0.6789193153381348, 'learning_rate': 1.3106575963718821e-05, 'epoch': 1.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 3900/11025 [35:28<43:42,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3267, 'grad_norm': 11.099424362182617, 'learning_rate': 1.2925170068027212e-05, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–‹      | 4000/11025 [36:05<43:10,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3286, 'grad_norm': 4.872696399688721, 'learning_rate': 1.2743764172335602e-05, 'epoch': 1.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 4100/11025 [36:42<42:38,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3947, 'grad_norm': 6.930663108825684, 'learning_rate': 1.2562358276643992e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 4200/11025 [37:18<41:51,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3097, 'grad_norm': 7.130961894989014, 'learning_rate': 1.2380952380952383e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 4300/11025 [37:55<41:15,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3374, 'grad_norm': 2.6293985843658447, 'learning_rate': 1.219954648526077e-05, 'epoch': 1.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 4400/11025 [38:32<40:38,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3487, 'grad_norm': 10.807917594909668, 'learning_rate': 1.2018140589569162e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4500/11025 [39:09<40:10,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2714, 'grad_norm': 13.368829727172852, 'learning_rate': 1.1836734693877552e-05, 'epoch': 1.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4600/11025 [39:46<39:24,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3488, 'grad_norm': 12.660006523132324, 'learning_rate': 1.1655328798185943e-05, 'epoch': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4700/11025 [40:23<38:53,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3389, 'grad_norm': 3.8340837955474854, 'learning_rate': 1.1473922902494332e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4800/11025 [41:00<38:17,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3701, 'grad_norm': 5.896657466888428, 'learning_rate': 1.1292517006802722e-05, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4900/11025 [41:37<37:39,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3346, 'grad_norm': 3.722095489501953, 'learning_rate': 1.1111111111111113e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 5000/11025 [42:14<37:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3358, 'grad_norm': 5.105600833892822, 'learning_rate': 1.0929705215419501e-05, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 5100/11025 [42:50<36:22,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3445, 'grad_norm': 14.764114379882812, 'learning_rate': 1.0748299319727893e-05, 'epoch': 1.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 5200/11025 [43:27<36:11,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3287, 'grad_norm': 17.771944046020508, 'learning_rate': 1.0566893424036282e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 5300/11025 [44:04<35:08,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3749, 'grad_norm': 0.7998957633972168, 'learning_rate': 1.0385487528344672e-05, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 5400/11025 [44:41<34:45,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2946, 'grad_norm': 23.48276138305664, 'learning_rate': 1.0204081632653063e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 5500/11025 [45:18<33:57,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3394, 'grad_norm': 9.033584594726562, 'learning_rate': 1.0022675736961451e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5600/11025 [45:55<33:18,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3193, 'grad_norm': 5.216367721557617, 'learning_rate': 9.841269841269842e-06, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5700/11025 [46:32<32:40,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3435, 'grad_norm': 4.628591060638428, 'learning_rate': 9.659863945578232e-06, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5800/11025 [47:09<32:03,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3136, 'grad_norm': 5.819119930267334, 'learning_rate': 9.478458049886621e-06, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5900/11025 [47:45<31:29,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3571, 'grad_norm': 2.2997682094573975, 'learning_rate': 9.297052154195013e-06, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 6000/11025 [48:22<30:53,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3386, 'grad_norm': 4.412736892700195, 'learning_rate': 9.115646258503402e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 6100/11025 [48:59<30:24,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3089, 'grad_norm': 3.178201675415039, 'learning_rate': 8.934240362811792e-06, 'epoch': 1.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 6200/11025 [49:36<29:35,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3738, 'grad_norm': 4.705409049987793, 'learning_rate': 8.752834467120183e-06, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 6300/11025 [50:13<29:06,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3306, 'grad_norm': 4.535904407501221, 'learning_rate': 8.571428571428571e-06, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 6400/11025 [50:50<28:42,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3291, 'grad_norm': 3.2317323684692383, 'learning_rate': 8.390022675736962e-06, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 6500/11025 [51:28<27:47,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3297, 'grad_norm': 0.8524833917617798, 'learning_rate': 8.208616780045352e-06, 'epoch': 1.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 6600/11025 [52:05<27:54,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3172, 'grad_norm': 10.946956634521484, 'learning_rate': 8.027210884353741e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6700/11025 [52:43<26:39,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3468, 'grad_norm': 4.7197418212890625, 'learning_rate': 7.845804988662133e-06, 'epoch': 1.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6800/11025 [53:20<25:52,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3357, 'grad_norm': 6.027444839477539, 'learning_rate': 7.664399092970522e-06, 'epoch': 1.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6900/11025 [53:57<25:14,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3185, 'grad_norm': 0.7744088172912598, 'learning_rate': 7.482993197278913e-06, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 7000/11025 [54:33<24:44,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.328, 'grad_norm': 11.245203971862793, 'learning_rate': 7.301587301587301e-06, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 7100/11025 [55:10<24:03,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3518, 'grad_norm': 1.8758736848831177, 'learning_rate': 7.120181405895692e-06, 'epoch': 1.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 7200/11025 [55:47<23:27,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3562, 'grad_norm': 11.788519859313965, 'learning_rate': 6.938775510204082e-06, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 7300/11025 [56:24<23:13,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3439, 'grad_norm': 0.6973892450332642, 'learning_rate': 6.757369614512473e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 7350/11025 [56:43<22:32,  2.72it/s]\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 7350/11025 [59:08<22:32,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37213829159736633, 'eval_accuracy': 0.8688888888888889, 'eval_f1': 0.8688888888888889, 'eval_precision': 0.8688888888888889, 'eval_recall': 0.8688888888888889, 'eval_runtime': 145.534, 'eval_samples_per_second': 86.578, 'eval_steps_per_second': 10.822, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b6/1mflrv1s5s9b5pj5n4cg2hjw0000gn/T/ipykernel_88913/2940528382.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 7400/11025 [59:29<22:10,  2.72it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3208, 'grad_norm': 1.186288833618164, 'learning_rate': 6.575963718820862e-06, 'epoch': 2.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 7500/11025 [1:00:06<21:35,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2767, 'grad_norm': 0.14747169613838196, 'learning_rate': 6.394557823129253e-06, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 7600/11025 [1:00:43<20:59,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2686, 'grad_norm': 27.704206466674805, 'learning_rate': 6.2131519274376415e-06, 'epoch': 2.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 7700/11025 [1:01:20<20:20,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3182, 'grad_norm': 0.252187579870224, 'learning_rate': 6.031746031746032e-06, 'epoch': 2.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7800/11025 [1:01:57<19:45,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2844, 'grad_norm': 15.414360046386719, 'learning_rate': 5.850340136054422e-06, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7900/11025 [1:02:33<19:07,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2705, 'grad_norm': 5.5390238761901855, 'learning_rate': 5.668934240362812e-06, 'epoch': 2.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 8000/11025 [1:03:10<18:34,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2916, 'grad_norm': 15.586450576782227, 'learning_rate': 5.487528344671202e-06, 'epoch': 2.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 8100/11025 [1:03:47<17:57,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3024, 'grad_norm': 21.718416213989258, 'learning_rate': 5.306122448979593e-06, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 8200/11025 [1:04:24<17:18,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2579, 'grad_norm': 5.794596195220947, 'learning_rate': 5.124716553287983e-06, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 8300/11025 [1:05:00<16:42,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3339, 'grad_norm': 4.677666664123535, 'learning_rate': 4.943310657596373e-06, 'epoch': 2.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 8400/11025 [1:05:37<16:01,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3004, 'grad_norm': 5.421273708343506, 'learning_rate': 4.761904761904762e-06, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 8500/11025 [1:06:14<15:35,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2872, 'grad_norm': 9.169305801391602, 'learning_rate': 4.580498866213152e-06, 'epoch': 2.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 8600/11025 [1:06:51<14:59,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3187, 'grad_norm': 0.3572438657283783, 'learning_rate': 4.399092970521542e-06, 'epoch': 2.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 8700/11025 [1:07:28<14:20,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2935, 'grad_norm': 4.875082015991211, 'learning_rate': 4.217687074829933e-06, 'epoch': 2.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 8800/11025 [1:08:05<13:50,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2992, 'grad_norm': 8.535686492919922, 'learning_rate': 4.036281179138322e-06, 'epoch': 2.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8900/11025 [1:08:42<13:04,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2633, 'grad_norm': 6.415994644165039, 'learning_rate': 3.854875283446712e-06, 'epoch': 2.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 9000/11025 [1:09:19<12:26,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2803, 'grad_norm': 7.441958427429199, 'learning_rate': 3.6734693877551024e-06, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 9100/11025 [1:09:56<11:49,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2915, 'grad_norm': 23.626115798950195, 'learning_rate': 3.492063492063492e-06, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 9200/11025 [1:10:33<11:12,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3585, 'grad_norm': 0.6630282998085022, 'learning_rate': 3.3106575963718824e-06, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 9300/11025 [1:11:10<10:34,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2724, 'grad_norm': 1.598374366760254, 'learning_rate': 3.1292517006802725e-06, 'epoch': 2.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 9400/11025 [1:11:46<09:57,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2619, 'grad_norm': 12.990674018859863, 'learning_rate': 2.947845804988662e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 9500/11025 [1:12:23<09:28,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2849, 'grad_norm': 3.587864637374878, 'learning_rate': 2.7664399092970525e-06, 'epoch': 2.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 9600/11025 [1:13:00<08:42,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2996, 'grad_norm': 0.6649580597877502, 'learning_rate': 2.5850340136054425e-06, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 9700/11025 [1:13:37<08:08,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3211, 'grad_norm': 0.2486201524734497, 'learning_rate': 2.4036281179138325e-06, 'epoch': 2.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 9800/11025 [1:14:14<07:30,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3019, 'grad_norm': 6.439983367919922, 'learning_rate': 2.222222222222222e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 9900/11025 [1:14:50<06:53,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2892, 'grad_norm': 0.2587137222290039, 'learning_rate': 2.0408163265306125e-06, 'epoch': 2.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 10000/11025 [1:15:28<06:17,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2977, 'grad_norm': 1.3160762786865234, 'learning_rate': 1.8594104308390023e-06, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 10100/11025 [1:16:04<05:39,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2561, 'grad_norm': 3.244680166244507, 'learning_rate': 1.6780045351473925e-06, 'epoch': 2.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 10200/11025 [1:16:41<05:03,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3216, 'grad_norm': 10.350027084350586, 'learning_rate': 1.4965986394557825e-06, 'epoch': 2.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 10300/11025 [1:17:18<04:26,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2802, 'grad_norm': 17.438474655151367, 'learning_rate': 1.3151927437641723e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 10400/11025 [1:17:55<03:49,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2922, 'grad_norm': 11.688016891479492, 'learning_rate': 1.1337868480725626e-06, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 10500/11025 [1:18:31<03:13,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3016, 'grad_norm': 22.057931900024414, 'learning_rate': 9.523809523809525e-07, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 10600/11025 [1:19:08<02:35,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2495, 'grad_norm': 14.829246520996094, 'learning_rate': 7.709750566893425e-07, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 10700/11025 [1:19:45<01:59,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3276, 'grad_norm': 16.814266204833984, 'learning_rate': 5.895691609977325e-07, 'epoch': 2.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 10800/11025 [1:20:22<01:22,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2694, 'grad_norm': 0.498172402381897, 'learning_rate': 4.0816326530612243e-07, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 10900/11025 [1:20:58<00:46,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3488, 'grad_norm': 6.004455089569092, 'learning_rate': 2.267573696145125e-07, 'epoch': 2.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 11000/11025 [1:21:35<00:09,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2798, 'grad_norm': 1.0642284154891968, 'learning_rate': 4.53514739229025e-08, 'epoch': 2.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11025/11025 [1:21:44<00:00,  2.72it/s]/var/folders/b6/1mflrv1s5s9b5pj5n4cg2hjw0000gn/T/ipykernel_88913/2940528382.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11025/11025 [1:24:12<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46143072843551636, 'eval_accuracy': 0.8668253968253968, 'eval_f1': 0.8668253968253968, 'eval_precision': 0.8668253968253968, 'eval_recall': 0.8668253968253968, 'eval_runtime': 145.0987, 'eval_samples_per_second': 86.837, 'eval_steps_per_second': 10.855, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11025/11025 [1:24:15<00:00,  2.18it/s]\n",
      "/var/folders/b6/1mflrv1s5s9b5pj5n4cg2hjw0000gn/T/ipykernel_88913/2940528382.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 5055.2793, 'train_samples_per_second': 17.447, 'train_steps_per_second': 2.181, 'train_loss': 0.3528726281060113, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1575/1575 [02:25<00:00, 10.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>eval_loss</th><th>eval_accuracy</th><th>eval_f1</th><th>eval_precision</th><th>eval_recall</th><th>eval_runtime</th><th>eval_samples_per_second</th><th>eval_steps_per_second</th><th>epoch</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.347226</td><td>0.860238</td><td>0.860238</td><td>0.860238</td><td>0.860238</td><td>145.968</td><td>86.32</td><td>10.79</td><td>3.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 9)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ eval_loss â”† eval_accur â”† eval_f1  â”† eval_preci â”† â€¦ â”† eval_runti â”† eval_sampl â”† eval_step â”† epoch â”‚\n",
       "â”‚ ---       â”† acy        â”† ---      â”† sion       â”†   â”† me         â”† es_per_sec â”† s_per_sec â”† ---   â”‚\n",
       "â”‚ f64       â”† ---        â”† f64      â”† ---        â”†   â”† ---        â”† ond        â”† ond       â”† f64   â”‚\n",
       "â”‚           â”† f64        â”†          â”† f64        â”†   â”† f64        â”† ---        â”† ---       â”†       â”‚\n",
       "â”‚           â”†            â”†          â”†            â”†   â”†            â”† f64        â”† f64       â”†       â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0.347226  â”† 0.860238   â”† 0.860238 â”† 0.860238   â”† â€¦ â”† 145.968    â”† 86.32      â”† 10.79     â”† 3.0   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_output = trainer.train()  # Returns a TrainOutput object\n",
    "train_metrics = train_output.metrics  # Contains train_runtime, train_loss, etc.\n",
    "\n",
    "# Assume trainer.evaluate() has been run and returned results\n",
    "eval_results = trainer.evaluate()  # Contains eval_runtime, eval_accuracy, etc.\n",
    "\n",
    "# Combine training and evaluation metrics\n",
    "#all_metrics = {**train_metrics, **eval_results}\n",
    "metrics = {**eval_results}\n",
    "\n",
    "# Create a Polars DataFrame\n",
    "df = pl.DataFrame(metrics)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
