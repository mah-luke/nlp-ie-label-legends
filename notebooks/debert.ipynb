{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for DeBERTa-v3-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import TokenList\n",
    "import polars as pl\n",
    "from stanza.models.common.doc import Token\n",
    "from label_legends.preprocess import create_conllu, holdout, load_conllu, load_data, load_train, transform, load_vectorizer, reverse_vocabulary, vocabulary, ids_to_tokens, tokens_to_ids, vectorize_tokens, strip_stopwords\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dependencies for this specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoConfig, DebertaV2Tokenizer, Trainer, TrainingArguments\n",
    "MODEL_NAME = 'microsoft/deberta-v3-base'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "tokenizer =DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "#DO I need the tokenizer here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (60_000, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>rewire_id</th><th>text</th><th>annotator</th><th>label_sexist</th><th>label_category</th><th>label_vector</th><th>split</th><th>tokens</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>0</td><td>&quot;sexism2022_english-0&quot;</td><td>&quot; I wonder what keeps that witc…</td><td>17</td><td>&quot;sexist&quot;</td><td>&quot;2. derogation&quot;</td><td>&quot;2.2 aggressive and emotive att…</td><td>&quot;train&quot;</td><td>[&quot;i&quot;, &quot;wonder&quot;, … &quot;😄&quot;]</td></tr><tr><td>1</td><td>&quot;sexism2022_english-0&quot;</td><td>&quot; I wonder what keeps that witc…</td><td>2</td><td>&quot;sexist&quot;</td><td>&quot;2. derogation&quot;</td><td>&quot;2.2 aggressive and emotive att…</td><td>&quot;train&quot;</td><td>[&quot;i&quot;, &quot;wonder&quot;, … &quot;😄&quot;]</td></tr><tr><td>10</td><td>&quot;sexism2022_english-100&quot;</td><td>&quot;Good for her! My grandson had …</td><td>3</td><td>&quot;not sexist&quot;</td><td>&quot;none&quot;</td><td>&quot;none&quot;</td><td>&quot;train&quot;</td><td>[&quot;good&quot;, &quot;for&quot;, … &quot;!&quot;]</td></tr><tr><td>100</td><td>&quot;sexism2022_english-10026&quot;</td><td>&quot;It is not insulting, it&#x27;s **ex…</td><td>14</td><td>&quot;sexist&quot;</td><td>&quot;2. derogation&quot;</td><td>&quot;2.1 descriptive attacks&quot;</td><td>&quot;test&quot;</td><td>[&quot;it&quot;, &quot;be&quot;, … &quot;.**&quot;]</td></tr><tr><td>1000</td><td>&quot;sexism2022_english-10297&quot;</td><td>&quot;The article said Madonna offer…</td><td>5</td><td>&quot;sexist&quot;</td><td>&quot;2. derogation&quot;</td><td>&quot;2.3 dehumanising attacks &amp; ove…</td><td>&quot;train&quot;</td><td>[&quot;the&quot;, &quot;article&quot;, … &quot;.&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>9995</td><td>&quot;sexism2022_english-12996&quot;</td><td>&quot;Shudder.. if you had to have s…</td><td>17</td><td>&quot;sexist&quot;</td><td>&quot;2. derogation&quot;</td><td>&quot;2.3 dehumanising attacks &amp; ove…</td><td>&quot;test&quot;</td><td>[&quot;shudder&quot;, &quot;..&quot;, … &quot;.&quot;]</td></tr><tr><td>9996</td><td>&quot;sexism2022_english-12997&quot;</td><td>&quot;You mean one that forces women…</td><td>6</td><td>&quot;not sexist&quot;</td><td>&quot;none&quot;</td><td>&quot;none&quot;</td><td>&quot;train&quot;</td><td>[&quot;you&quot;, &quot;mean&quot;, … &quot;?&quot;]</td></tr><tr><td>9997</td><td>&quot;sexism2022_english-12997&quot;</td><td>&quot;You mean one that forces women…</td><td>4</td><td>&quot;not sexist&quot;</td><td>&quot;none&quot;</td><td>&quot;none&quot;</td><td>&quot;train&quot;</td><td>[&quot;you&quot;, &quot;mean&quot;, … &quot;?&quot;]</td></tr><tr><td>9998</td><td>&quot;sexism2022_english-12997&quot;</td><td>&quot;You mean one that forces women…</td><td>2</td><td>&quot;sexist&quot;</td><td>&quot;3. animosity&quot;</td><td>&quot;3.2 immutable gender differenc…</td><td>&quot;train&quot;</td><td>[&quot;you&quot;, &quot;mean&quot;, … &quot;?&quot;]</td></tr><tr><td>9999</td><td>&quot;sexism2022_english-12998&quot;</td><td>&quot;Gasoline. The answer 60% of Am…</td><td>9</td><td>&quot;sexist&quot;</td><td>&quot;1. threats, plans to harm and …</td><td>&quot;1.1 threats of harm&quot;</td><td>&quot;train&quot;</td><td>[&quot;gasoline&quot;, &quot;.&quot;, … &quot;.&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (60_000, 9)\n",
       "┌──────┬─────────────┬─────────────┬───────────┬───┬─────────────┬────────────┬───────┬────────────┐\n",
       "│ id   ┆ rewire_id   ┆ text        ┆ annotator ┆ … ┆ label_categ ┆ label_vect ┆ split ┆ tokens     │\n",
       "│ ---  ┆ ---         ┆ ---         ┆ ---       ┆   ┆ ory         ┆ or         ┆ ---   ┆ ---        │\n",
       "│ i64  ┆ str         ┆ str         ┆ i64       ┆   ┆ ---         ┆ ---        ┆ str   ┆ list[str]  │\n",
       "│      ┆             ┆             ┆           ┆   ┆ str         ┆ str        ┆       ┆            │\n",
       "╞══════╪═════════════╪═════════════╪═══════════╪═══╪═════════════╪════════════╪═══════╪════════════╡\n",
       "│ 0    ┆ sexism2022_ ┆ I wonder    ┆ 17        ┆ … ┆ 2.          ┆ 2.2        ┆ train ┆ [\"i\",      │\n",
       "│      ┆ english-0   ┆ what keeps  ┆           ┆   ┆ derogation  ┆ aggressive ┆       ┆ \"wonder\",  │\n",
       "│      ┆             ┆ that witc…  ┆           ┆   ┆             ┆ and        ┆       ┆ … \"😄\"]    │\n",
       "│      ┆             ┆             ┆           ┆   ┆             ┆ emotive    ┆       ┆            │\n",
       "│      ┆             ┆             ┆           ┆   ┆             ┆ att…       ┆       ┆            │\n",
       "│ 1    ┆ sexism2022_ ┆ I wonder    ┆ 2         ┆ … ┆ 2.          ┆ 2.2        ┆ train ┆ [\"i\",      │\n",
       "│      ┆ english-0   ┆ what keeps  ┆           ┆   ┆ derogation  ┆ aggressive ┆       ┆ \"wonder\",  │\n",
       "│      ┆             ┆ that witc…  ┆           ┆   ┆             ┆ and        ┆       ┆ … \"😄\"]    │\n",
       "│      ┆             ┆             ┆           ┆   ┆             ┆ emotive    ┆       ┆            │\n",
       "│      ┆             ┆             ┆           ┆   ┆             ┆ att…       ┆       ┆            │\n",
       "│ 10   ┆ sexism2022_ ┆ Good for    ┆ 3         ┆ … ┆ none        ┆ none       ┆ train ┆ [\"good\",   │\n",
       "│      ┆ english-100 ┆ her! My     ┆           ┆   ┆             ┆            ┆       ┆ \"for\", …   │\n",
       "│      ┆             ┆ grandson    ┆           ┆   ┆             ┆            ┆       ┆ \"!\"]       │\n",
       "│      ┆             ┆ had …       ┆           ┆   ┆             ┆            ┆       ┆            │\n",
       "│ 100  ┆ sexism2022_ ┆ It is not   ┆ 14        ┆ … ┆ 2.          ┆ 2.1 descri ┆ test  ┆ [\"it\",     │\n",
       "│      ┆ english-100 ┆ insulting,  ┆           ┆   ┆ derogation  ┆ ptive      ┆       ┆ \"be\", …    │\n",
       "│      ┆ 26          ┆ it's **ex…  ┆           ┆   ┆             ┆ attacks    ┆       ┆ \".**\"]     │\n",
       "│ 1000 ┆ sexism2022_ ┆ The article ┆ 5         ┆ … ┆ 2.          ┆ 2.3 dehuma ┆ train ┆ [\"the\",    │\n",
       "│      ┆ english-102 ┆ said        ┆           ┆   ┆ derogation  ┆ nising     ┆       ┆ \"article\", │\n",
       "│      ┆ 97          ┆ Madonna     ┆           ┆   ┆             ┆ attacks &  ┆       ┆ … \".\"]     │\n",
       "│      ┆             ┆ offer…      ┆           ┆   ┆             ┆ ove…       ┆       ┆            │\n",
       "│ …    ┆ …           ┆ …           ┆ …         ┆ … ┆ …           ┆ …          ┆ …     ┆ …          │\n",
       "│ 9995 ┆ sexism2022_ ┆ Shudder..   ┆ 17        ┆ … ┆ 2.          ┆ 2.3 dehuma ┆ test  ┆ [\"shudder\" │\n",
       "│      ┆ english-129 ┆ if you had  ┆           ┆   ┆ derogation  ┆ nising     ┆       ┆ , \"..\", …  │\n",
       "│      ┆ 96          ┆ to have s…  ┆           ┆   ┆             ┆ attacks &  ┆       ┆ \".\"]       │\n",
       "│      ┆             ┆             ┆           ┆   ┆             ┆ ove…       ┆       ┆            │\n",
       "│ 9996 ┆ sexism2022_ ┆ You mean    ┆ 6         ┆ … ┆ none        ┆ none       ┆ train ┆ [\"you\",    │\n",
       "│      ┆ english-129 ┆ one that    ┆           ┆   ┆             ┆            ┆       ┆ \"mean\", …  │\n",
       "│      ┆ 97          ┆ forces      ┆           ┆   ┆             ┆            ┆       ┆ \"?\"]       │\n",
       "│      ┆             ┆ women…      ┆           ┆   ┆             ┆            ┆       ┆            │\n",
       "│ 9997 ┆ sexism2022_ ┆ You mean    ┆ 4         ┆ … ┆ none        ┆ none       ┆ train ┆ [\"you\",    │\n",
       "│      ┆ english-129 ┆ one that    ┆           ┆   ┆             ┆            ┆       ┆ \"mean\", …  │\n",
       "│      ┆ 97          ┆ forces      ┆           ┆   ┆             ┆            ┆       ┆ \"?\"]       │\n",
       "│      ┆             ┆ women…      ┆           ┆   ┆             ┆            ┆       ┆            │\n",
       "│ 9998 ┆ sexism2022_ ┆ You mean    ┆ 2         ┆ … ┆ 3.          ┆ 3.2        ┆ train ┆ [\"you\",    │\n",
       "│      ┆ english-129 ┆ one that    ┆           ┆   ┆ animosity   ┆ immutable  ┆       ┆ \"mean\", …  │\n",
       "│      ┆ 97          ┆ forces      ┆           ┆   ┆             ┆ gender     ┆       ┆ \"?\"]       │\n",
       "│      ┆             ┆ women…      ┆           ┆   ┆             ┆ differenc… ┆       ┆            │\n",
       "│ 9999 ┆ sexism2022_ ┆ Gasoline.   ┆ 9         ┆ … ┆ 1. threats, ┆ 1.1        ┆ train ┆ [\"gasoline │\n",
       "│      ┆ english-129 ┆ The answer  ┆           ┆   ┆ plans to    ┆ threats of ┆       ┆ \", \".\", …  │\n",
       "│      ┆ 98          ┆ 60% of Am…  ┆           ┆   ┆ harm and …  ┆ harm       ┆       ┆ \".\"]       │\n",
       "└──────┴─────────────┴─────────────┴───────────┴───┴─────────────┴────────────┴───────┴────────────┘"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, tra = holdout()\n",
    "tra = transform(tra)\n",
    "val = transform(val)\n",
    "\n",
    "# Convert 'label' column from string '0' and '1' to integer 0 and 1\n",
    "tra = tra.with_columns(\n",
    "    polars.col(\"label\").cast(polars.Int32)\n",
    ")\n",
    "val = val.with_columns(\n",
    "    polars.col(\"label\").cast(polars.Int32)\n",
    ")\n",
    "\n",
    "train_texts = tra[\"text\"].to_list()\n",
    "train_labels = tra[\"label\"].to_list()\n",
    "val_texts = val[\"text\"].to_list()\n",
    "val_labels = val[\"label\"].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3675/11025 [15:43:17<31:26:34, 15.40s/it]\n",
      "\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "train_encodings = tokenizer(\n",
    "    train_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,  # Adjust this as needed\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    val_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SexistDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    \n",
    "    \n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"micro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SexistDataset(train_encodings, train_labels)\n",
    "val_dataset = SexistDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/retipeter/Documents/TU Wien/NLP/nlp-ie-label-legends/.venv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/b6/1mflrv1s5s9b5pj5n4cg2hjw0000gn/T/ipykernel_88913/1078182425.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "  1%|          | 119/11025 [12:16:45<1125:22:25, 371.48s/it]\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"epoch\",  # Keep this for evaluation at the end of each epoch\n",
    "    logging_steps=100,  # Log less frequently than every step, but more often than every epoch\n",
    "    save_strategy=\"epoch\",  # Save checkpoints at the end of each epoch\n",
    "    load_best_model_at_end=True,  # Load best model based on evaluation loss\n",
    "    metric_for_best_model='eval_loss',  # Track evaluation loss for best model\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "#trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11025 [00:00<?, ?it/s]/var/folders/b6/1mflrv1s5s9b5pj5n4cg2hjw0000gn/T/ipykernel_88913/2940528382.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "  1%|          | 100/11025 [00:36<1:06:37,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5642, 'grad_norm': 2.3384995460510254, 'learning_rate': 1.981859410430839e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 200/11025 [01:13<1:06:03,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5272, 'grad_norm': 15.648771286010742, 'learning_rate': 1.963718820861678e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 300/11025 [01:49<1:05:22,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5822, 'grad_norm': 1.468311071395874, 'learning_rate': 1.945578231292517e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 400/11025 [02:26<1:04:53,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5128, 'grad_norm': 1.9529191255569458, 'learning_rate': 1.9274376417233563e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 500/11025 [03:03<1:04:26,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4616, 'grad_norm': 3.1888108253479004, 'learning_rate': 1.9092970521541953e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 600/11025 [03:39<1:03:42,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4432, 'grad_norm': 12.392617225646973, 'learning_rate': 1.8911564625850343e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 700/11025 [04:16<1:03:10,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.453, 'grad_norm': 2.466106414794922, 'learning_rate': 1.8730158730158732e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 800/11025 [04:53<1:02:33,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4374, 'grad_norm': 11.236799240112305, 'learning_rate': 1.8548752834467122e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 900/11025 [05:30<1:01:58,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.436, 'grad_norm': 6.2112321853637695, 'learning_rate': 1.836734693877551e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1000/11025 [06:06<1:01:17,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4448, 'grad_norm': 10.407325744628906, 'learning_rate': 1.81859410430839e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 1100/11025 [06:43<1:00:38,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4364, 'grad_norm': 3.7003865242004395, 'learning_rate': 1.8004535147392294e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1200/11025 [07:20<1:00:05,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3919, 'grad_norm': 1.5171334743499756, 'learning_rate': 1.782312925170068e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1300/11025 [07:56<1:00:10,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.434, 'grad_norm': 8.173460960388184, 'learning_rate': 1.7641723356009073e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1400/11025 [08:33<58:49,  2.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4301, 'grad_norm': 3.084192991256714, 'learning_rate': 1.7460317460317463e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 1500/11025 [09:10<58:15,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4271, 'grad_norm': 4.467639923095703, 'learning_rate': 1.7278911564625852e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1600/11025 [09:46<57:39,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4014, 'grad_norm': 4.073261260986328, 'learning_rate': 1.7097505668934242e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1700/11025 [19:27<3:49:59,  1.48s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4436, 'grad_norm': 5.532982349395752, 'learning_rate': 1.691609977324263e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 1800/11025 [20:04<56:55,  2.70it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4133, 'grad_norm': 4.643570423126221, 'learning_rate': 1.673469387755102e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1900/11025 [20:41<55:35,  2.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.385, 'grad_norm': 2.6342008113861084, 'learning_rate': 1.655328798185941e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2000/11025 [21:18<55:01,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4044, 'grad_norm': 13.557908058166504, 'learning_rate': 1.63718820861678e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 2100/11025 [21:56<54:47,  2.72it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3847, 'grad_norm': 4.300295352935791, 'learning_rate': 1.6190476190476193e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 2200/11025 [22:32<54:23,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4002, 'grad_norm': 3.9787437915802, 'learning_rate': 1.6009070294784583e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2300/11025 [23:09<53:35,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4527, 'grad_norm': 8.525747299194336, 'learning_rate': 1.5827664399092972e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2400/11025 [23:46<53:06,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.435, 'grad_norm': 8.526215553283691, 'learning_rate': 1.5646258503401362e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2500/11025 [24:23<52:22,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3802, 'grad_norm': 28.95743751525879, 'learning_rate': 1.546485260770975e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 2600/11025 [25:00<51:44,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4411, 'grad_norm': 7.04342794418335, 'learning_rate': 1.528344671201814e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2700/11025 [25:37<51:14,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3894, 'grad_norm': 6.365671157836914, 'learning_rate': 1.510204081632653e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2800/11025 [26:14<50:30,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4057, 'grad_norm': 3.6063196659088135, 'learning_rate': 1.4920634920634922e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 2900/11025 [26:51<50:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.405, 'grad_norm': 4.066201210021973, 'learning_rate': 1.4739229024943311e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3000/11025 [27:28<49:15,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3891, 'grad_norm': 2.5872621536254883, 'learning_rate': 1.4557823129251703e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 3100/11025 [28:05<48:49,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3744, 'grad_norm': 1.2128922939300537, 'learning_rate': 1.4376417233560092e-05, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 3200/11025 [28:42<48:09,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3647, 'grad_norm': 3.478449821472168, 'learning_rate': 1.4195011337868484e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 3300/11025 [29:19<47:48,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3944, 'grad_norm': 4.648478984832764, 'learning_rate': 1.4013605442176872e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3400/11025 [29:56<46:52,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4202, 'grad_norm': 2.7207529544830322, 'learning_rate': 1.3832199546485261e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3500/11025 [30:33<46:13,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3414, 'grad_norm': 0.6616837978363037, 'learning_rate': 1.3650793650793652e-05, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3600/11025 [31:09<45:40,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4137, 'grad_norm': 8.376431465148926, 'learning_rate': 1.3469387755102042e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3675/11025 [31:37<45:16,  2.71it/s]\n",
      " 33%|███▎      | 3675/11025 [34:02<45:16,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34722602367401123, 'eval_accuracy': 0.8602380952380952, 'eval_f1': 0.8602380952380952, 'eval_precision': 0.8602380952380952, 'eval_recall': 0.8602380952380952, 'eval_runtime': 145.2868, 'eval_samples_per_second': 86.725, 'eval_steps_per_second': 10.841, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b6/1mflrv1s5s9b5pj5n4cg2hjw0000gn/T/ipykernel_88913/2940528382.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 34%|███▎      | 3700/11025 [34:14<46:07,  2.65it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4049, 'grad_norm': 1.6981748342514038, 'learning_rate': 1.3287981859410433e-05, 'epoch': 1.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3800/11025 [34:51<44:27,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3576, 'grad_norm': 0.6789193153381348, 'learning_rate': 1.3106575963718821e-05, 'epoch': 1.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 3900/11025 [35:28<43:42,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3267, 'grad_norm': 11.099424362182617, 'learning_rate': 1.2925170068027212e-05, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4000/11025 [36:05<43:10,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3286, 'grad_norm': 4.872696399688721, 'learning_rate': 1.2743764172335602e-05, 'epoch': 1.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 4100/11025 [36:42<42:38,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3947, 'grad_norm': 6.930663108825684, 'learning_rate': 1.2562358276643992e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 4200/11025 [37:18<41:51,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3097, 'grad_norm': 7.130961894989014, 'learning_rate': 1.2380952380952383e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 4300/11025 [37:55<41:15,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3374, 'grad_norm': 2.6293985843658447, 'learning_rate': 1.219954648526077e-05, 'epoch': 1.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 4400/11025 [38:32<40:38,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3487, 'grad_norm': 10.807917594909668, 'learning_rate': 1.2018140589569162e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4500/11025 [39:09<40:10,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2714, 'grad_norm': 13.368829727172852, 'learning_rate': 1.1836734693877552e-05, 'epoch': 1.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4600/11025 [39:46<39:24,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3488, 'grad_norm': 12.660006523132324, 'learning_rate': 1.1655328798185943e-05, 'epoch': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4700/11025 [40:23<38:53,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3389, 'grad_norm': 3.8340837955474854, 'learning_rate': 1.1473922902494332e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4800/11025 [41:00<38:17,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3701, 'grad_norm': 5.896657466888428, 'learning_rate': 1.1292517006802722e-05, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4900/11025 [41:37<37:39,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3346, 'grad_norm': 3.722095489501953, 'learning_rate': 1.1111111111111113e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 5000/11025 [42:14<37:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3358, 'grad_norm': 5.105600833892822, 'learning_rate': 1.0929705215419501e-05, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 5100/11025 [42:50<36:22,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3445, 'grad_norm': 14.764114379882812, 'learning_rate': 1.0748299319727893e-05, 'epoch': 1.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 5200/11025 [43:27<36:11,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3287, 'grad_norm': 17.771944046020508, 'learning_rate': 1.0566893424036282e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 5300/11025 [44:04<35:08,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3749, 'grad_norm': 0.7998957633972168, 'learning_rate': 1.0385487528344672e-05, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 5400/11025 [44:41<34:45,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2946, 'grad_norm': 23.48276138305664, 'learning_rate': 1.0204081632653063e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 5500/11025 [45:18<33:57,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3394, 'grad_norm': 9.033584594726562, 'learning_rate': 1.0022675736961451e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 5600/11025 [45:55<33:18,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3193, 'grad_norm': 5.216367721557617, 'learning_rate': 9.841269841269842e-06, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 5700/11025 [46:32<32:40,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3435, 'grad_norm': 4.628591060638428, 'learning_rate': 9.659863945578232e-06, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 5800/11025 [47:09<32:03,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3136, 'grad_norm': 5.819119930267334, 'learning_rate': 9.478458049886621e-06, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 5900/11025 [47:45<31:29,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3571, 'grad_norm': 2.2997682094573975, 'learning_rate': 9.297052154195013e-06, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 6000/11025 [48:22<30:53,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3386, 'grad_norm': 4.412736892700195, 'learning_rate': 9.115646258503402e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 6100/11025 [48:59<30:24,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3089, 'grad_norm': 3.178201675415039, 'learning_rate': 8.934240362811792e-06, 'epoch': 1.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 6200/11025 [49:36<29:35,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3738, 'grad_norm': 4.705409049987793, 'learning_rate': 8.752834467120183e-06, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 6300/11025 [50:13<29:06,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3306, 'grad_norm': 4.535904407501221, 'learning_rate': 8.571428571428571e-06, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 6400/11025 [50:50<28:42,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3291, 'grad_norm': 3.2317323684692383, 'learning_rate': 8.390022675736962e-06, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 6500/11025 [51:28<27:47,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3297, 'grad_norm': 0.8524833917617798, 'learning_rate': 8.208616780045352e-06, 'epoch': 1.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 6600/11025 [52:05<27:54,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3172, 'grad_norm': 10.946956634521484, 'learning_rate': 8.027210884353741e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 6700/11025 [52:43<26:39,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3468, 'grad_norm': 4.7197418212890625, 'learning_rate': 7.845804988662133e-06, 'epoch': 1.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 6800/11025 [53:20<25:52,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3357, 'grad_norm': 6.027444839477539, 'learning_rate': 7.664399092970522e-06, 'epoch': 1.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 6900/11025 [53:57<25:14,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3185, 'grad_norm': 0.7744088172912598, 'learning_rate': 7.482993197278913e-06, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 7000/11025 [54:33<24:44,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.328, 'grad_norm': 11.245203971862793, 'learning_rate': 7.301587301587301e-06, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 7100/11025 [55:10<24:03,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3518, 'grad_norm': 1.8758736848831177, 'learning_rate': 7.120181405895692e-06, 'epoch': 1.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 7200/11025 [55:47<23:27,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3562, 'grad_norm': 11.788519859313965, 'learning_rate': 6.938775510204082e-06, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 7300/11025 [56:24<23:13,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3439, 'grad_norm': 0.6973892450332642, 'learning_rate': 6.757369614512473e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 7350/11025 [56:43<22:32,  2.72it/s]\n",
      " 67%|██████▋   | 7350/11025 [59:08<22:32,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37213829159736633, 'eval_accuracy': 0.8688888888888889, 'eval_f1': 0.8688888888888889, 'eval_precision': 0.8688888888888889, 'eval_recall': 0.8688888888888889, 'eval_runtime': 145.534, 'eval_samples_per_second': 86.578, 'eval_steps_per_second': 10.822, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b6/1mflrv1s5s9b5pj5n4cg2hjw0000gn/T/ipykernel_88913/2940528382.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 67%|██████▋   | 7400/11025 [59:29<22:10,  2.72it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3208, 'grad_norm': 1.186288833618164, 'learning_rate': 6.575963718820862e-06, 'epoch': 2.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 7500/11025 [1:00:06<21:35,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2767, 'grad_norm': 0.14747169613838196, 'learning_rate': 6.394557823129253e-06, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 7600/11025 [1:00:43<20:59,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2686, 'grad_norm': 27.704206466674805, 'learning_rate': 6.2131519274376415e-06, 'epoch': 2.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 7700/11025 [1:01:20<20:20,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3182, 'grad_norm': 0.252187579870224, 'learning_rate': 6.031746031746032e-06, 'epoch': 2.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 7800/11025 [1:01:57<19:45,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2844, 'grad_norm': 15.414360046386719, 'learning_rate': 5.850340136054422e-06, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 7900/11025 [1:02:33<19:07,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2705, 'grad_norm': 5.5390238761901855, 'learning_rate': 5.668934240362812e-06, 'epoch': 2.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 8000/11025 [1:03:10<18:34,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2916, 'grad_norm': 15.586450576782227, 'learning_rate': 5.487528344671202e-06, 'epoch': 2.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 8100/11025 [1:03:47<17:57,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3024, 'grad_norm': 21.718416213989258, 'learning_rate': 5.306122448979593e-06, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 8200/11025 [1:04:24<17:18,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2579, 'grad_norm': 5.794596195220947, 'learning_rate': 5.124716553287983e-06, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 8300/11025 [1:05:00<16:42,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3339, 'grad_norm': 4.677666664123535, 'learning_rate': 4.943310657596373e-06, 'epoch': 2.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 8400/11025 [1:05:37<16:01,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3004, 'grad_norm': 5.421273708343506, 'learning_rate': 4.761904761904762e-06, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 8500/11025 [1:06:14<15:35,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2872, 'grad_norm': 9.169305801391602, 'learning_rate': 4.580498866213152e-06, 'epoch': 2.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 8600/11025 [1:06:51<14:59,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3187, 'grad_norm': 0.3572438657283783, 'learning_rate': 4.399092970521542e-06, 'epoch': 2.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 8700/11025 [1:07:28<14:20,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2935, 'grad_norm': 4.875082015991211, 'learning_rate': 4.217687074829933e-06, 'epoch': 2.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 8800/11025 [1:08:05<13:50,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2992, 'grad_norm': 8.535686492919922, 'learning_rate': 4.036281179138322e-06, 'epoch': 2.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 8900/11025 [1:08:42<13:04,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2633, 'grad_norm': 6.415994644165039, 'learning_rate': 3.854875283446712e-06, 'epoch': 2.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 9000/11025 [1:09:19<12:26,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2803, 'grad_norm': 7.441958427429199, 'learning_rate': 3.6734693877551024e-06, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 9100/11025 [1:09:56<11:49,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2915, 'grad_norm': 23.626115798950195, 'learning_rate': 3.492063492063492e-06, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 9200/11025 [1:10:33<11:12,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3585, 'grad_norm': 0.6630282998085022, 'learning_rate': 3.3106575963718824e-06, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 9300/11025 [1:11:10<10:34,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2724, 'grad_norm': 1.598374366760254, 'learning_rate': 3.1292517006802725e-06, 'epoch': 2.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 9400/11025 [1:11:46<09:57,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2619, 'grad_norm': 12.990674018859863, 'learning_rate': 2.947845804988662e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 9500/11025 [1:12:23<09:28,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2849, 'grad_norm': 3.587864637374878, 'learning_rate': 2.7664399092970525e-06, 'epoch': 2.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 9600/11025 [1:13:00<08:42,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2996, 'grad_norm': 0.6649580597877502, 'learning_rate': 2.5850340136054425e-06, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 9700/11025 [1:13:37<08:08,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3211, 'grad_norm': 0.2486201524734497, 'learning_rate': 2.4036281179138325e-06, 'epoch': 2.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 9800/11025 [1:14:14<07:30,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3019, 'grad_norm': 6.439983367919922, 'learning_rate': 2.222222222222222e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 9900/11025 [1:14:50<06:53,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2892, 'grad_norm': 0.2587137222290039, 'learning_rate': 2.0408163265306125e-06, 'epoch': 2.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10000/11025 [1:15:28<06:17,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2977, 'grad_norm': 1.3160762786865234, 'learning_rate': 1.8594104308390023e-06, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 10100/11025 [1:16:04<05:39,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2561, 'grad_norm': 3.244680166244507, 'learning_rate': 1.6780045351473925e-06, 'epoch': 2.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 10200/11025 [1:16:41<05:03,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3216, 'grad_norm': 10.350027084350586, 'learning_rate': 1.4965986394557825e-06, 'epoch': 2.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 10300/11025 [1:17:18<04:26,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2802, 'grad_norm': 17.438474655151367, 'learning_rate': 1.3151927437641723e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 10400/11025 [1:17:55<03:49,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2922, 'grad_norm': 11.688016891479492, 'learning_rate': 1.1337868480725626e-06, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 10500/11025 [1:18:31<03:13,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3016, 'grad_norm': 22.057931900024414, 'learning_rate': 9.523809523809525e-07, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 10600/11025 [1:19:08<02:35,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2495, 'grad_norm': 14.829246520996094, 'learning_rate': 7.709750566893425e-07, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 10700/11025 [1:19:45<01:59,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3276, 'grad_norm': 16.814266204833984, 'learning_rate': 5.895691609977325e-07, 'epoch': 2.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 10800/11025 [1:20:22<01:22,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2694, 'grad_norm': 0.498172402381897, 'learning_rate': 4.0816326530612243e-07, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 10900/11025 [1:20:58<00:46,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3488, 'grad_norm': 6.004455089569092, 'learning_rate': 2.267573696145125e-07, 'epoch': 2.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 11000/11025 [1:21:35<00:09,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2798, 'grad_norm': 1.0642284154891968, 'learning_rate': 4.53514739229025e-08, 'epoch': 2.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11025/11025 [1:21:44<00:00,  2.72it/s]/var/folders/b6/1mflrv1s5s9b5pj5n4cg2hjw0000gn/T/ipykernel_88913/2940528382.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "100%|██████████| 11025/11025 [1:24:12<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46143072843551636, 'eval_accuracy': 0.8668253968253968, 'eval_f1': 0.8668253968253968, 'eval_precision': 0.8668253968253968, 'eval_recall': 0.8668253968253968, 'eval_runtime': 145.0987, 'eval_samples_per_second': 86.837, 'eval_steps_per_second': 10.855, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11025/11025 [1:24:15<00:00,  2.18it/s]\n",
      "/var/folders/b6/1mflrv1s5s9b5pj5n4cg2hjw0000gn/T/ipykernel_88913/2940528382.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 5055.2793, 'train_samples_per_second': 17.447, 'train_steps_per_second': 2.181, 'train_loss': 0.3528726281060113, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1575/1575 [02:25<00:00, 10.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>eval_loss</th><th>eval_accuracy</th><th>eval_f1</th><th>eval_precision</th><th>eval_recall</th><th>eval_runtime</th><th>eval_samples_per_second</th><th>eval_steps_per_second</th><th>epoch</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.347226</td><td>0.860238</td><td>0.860238</td><td>0.860238</td><td>0.860238</td><td>145.968</td><td>86.32</td><td>10.79</td><td>3.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 9)\n",
       "┌───────────┬────────────┬──────────┬────────────┬───┬────────────┬────────────┬───────────┬───────┐\n",
       "│ eval_loss ┆ eval_accur ┆ eval_f1  ┆ eval_preci ┆ … ┆ eval_runti ┆ eval_sampl ┆ eval_step ┆ epoch │\n",
       "│ ---       ┆ acy        ┆ ---      ┆ sion       ┆   ┆ me         ┆ es_per_sec ┆ s_per_sec ┆ ---   │\n",
       "│ f64       ┆ ---        ┆ f64      ┆ ---        ┆   ┆ ---        ┆ ond        ┆ ond       ┆ f64   │\n",
       "│           ┆ f64        ┆          ┆ f64        ┆   ┆ f64        ┆ ---        ┆ ---       ┆       │\n",
       "│           ┆            ┆          ┆            ┆   ┆            ┆ f64        ┆ f64       ┆       │\n",
       "╞═══════════╪════════════╪══════════╪════════════╪═══╪════════════╪════════════╪═══════════╪═══════╡\n",
       "│ 0.347226  ┆ 0.860238   ┆ 0.860238 ┆ 0.860238   ┆ … ┆ 145.968    ┆ 86.32      ┆ 10.79     ┆ 3.0   │\n",
       "└───────────┴────────────┴──────────┴────────────┴───┴────────────┴────────────┴───────────┴───────┘"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_output = trainer.train()  # Returns a TrainOutput object\n",
    "train_metrics = train_output.metrics  # Contains train_runtime, train_loss, etc.\n",
    "\n",
    "# Assume trainer.evaluate() has been run and returned results\n",
    "eval_results = trainer.evaluate()  # Contains eval_runtime, eval_accuracy, etc.\n",
    "\n",
    "# Combine training and evaluation metrics\n",
    "#all_metrics = {**train_metrics, **eval_results}\n",
    "metrics = {**eval_results}\n",
    "\n",
    "# Create a Polars DataFrame\n",
    "df = pl.DataFrame(metrics)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
