{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\noika\\Documents\\NLP project\\label_legends\\nlp-ie-label-legends\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#dependencies\n",
    "import pandas as pd\n",
    "from label_legends.preprocess import load_test, load_data, transform, load_train\n",
    "from label_legends.result import load_predictions, get_current, load_predictions\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotator</th>\n",
       "      <th>label_sexist</th>\n",
       "      <th>label_category</th>\n",
       "      <th>label_vector</th>\n",
       "      <th>split</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sexism2022_english-0</td>\n",
       "      <td>I wonder what keeps that witch looking quite ...</td>\n",
       "      <td>17</td>\n",
       "      <td>sexist</td>\n",
       "      <td>2. derogation</td>\n",
       "      <td>2.2 aggressive and emotive attacks</td>\n",
       "      <td>train</td>\n",
       "      <td>[i, wonder, what, keep, that, witch, look, qui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sexism2022_english-0</td>\n",
       "      <td>I wonder what keeps that witch looking quite ...</td>\n",
       "      <td>2</td>\n",
       "      <td>sexist</td>\n",
       "      <td>2. derogation</td>\n",
       "      <td>2.2 aggressive and emotive attacks</td>\n",
       "      <td>train</td>\n",
       "      <td>[i, wonder, what, keep, that, witch, look, qui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>sexism2022_english-100</td>\n",
       "      <td>Good for her! My grandson had acid reflux, but...</td>\n",
       "      <td>3</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "      <td>[good, for, her, !, my, grandson, have, acid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>sexism2022_english-10297</td>\n",
       "      <td>The article said Madonna offered to give anyon...</td>\n",
       "      <td>5</td>\n",
       "      <td>sexist</td>\n",
       "      <td>2. derogation</td>\n",
       "      <td>2.3 dehumanising attacks &amp; overt sexual object...</td>\n",
       "      <td>train</td>\n",
       "      <td>[the, article, say, madonna, offer, to, give, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>sexism2022_english-12998</td>\n",
       "      <td>Gasoline. The answer 60% of America gives when...</td>\n",
       "      <td>8</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "      <td>[gasoline, ., the, answer, 60, %, of, america,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>9992</td>\n",
       "      <td>sexism2022_english-12995</td>\n",
       "      <td>haha woman suck amirite. it's like, obviously ...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexist</td>\n",
       "      <td>2. derogation</td>\n",
       "      <td>2.1 descriptive attacks</td>\n",
       "      <td>train</td>\n",
       "      <td>[haha, woman, suck, amirite, ., it, be, like, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>9996</td>\n",
       "      <td>sexism2022_english-12997</td>\n",
       "      <td>You mean one that forces women to like wimpy f...</td>\n",
       "      <td>6</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "      <td>[you, mean, one, that, force, woman, to, like,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>9997</td>\n",
       "      <td>sexism2022_english-12997</td>\n",
       "      <td>You mean one that forces women to like wimpy f...</td>\n",
       "      <td>4</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "      <td>[you, mean, one, that, force, woman, to, like,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>9998</td>\n",
       "      <td>sexism2022_english-12997</td>\n",
       "      <td>You mean one that forces women to like wimpy f...</td>\n",
       "      <td>2</td>\n",
       "      <td>sexist</td>\n",
       "      <td>3. animosity</td>\n",
       "      <td>3.2 immutable gender differences and gender st...</td>\n",
       "      <td>train</td>\n",
       "      <td>[you, mean, one, that, force, woman, to, like,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9999</td>\n",
       "      <td>sexism2022_english-12998</td>\n",
       "      <td>Gasoline. The answer 60% of America gives when...</td>\n",
       "      <td>9</td>\n",
       "      <td>sexist</td>\n",
       "      <td>1. threats, plans to harm and incitement</td>\n",
       "      <td>1.1 threats of harm</td>\n",
       "      <td>train</td>\n",
       "      <td>[gasoline, ., the, answer, 60, %, of, america,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                 rewire_id  \\\n",
       "0          0      sexism2022_english-0   \n",
       "1          1      sexism2022_english-0   \n",
       "2         10    sexism2022_english-100   \n",
       "3       1000  sexism2022_english-10297   \n",
       "4      10000  sexism2022_english-12998   \n",
       "...      ...                       ...   \n",
       "41995   9992  sexism2022_english-12995   \n",
       "41996   9996  sexism2022_english-12997   \n",
       "41997   9997  sexism2022_english-12997   \n",
       "41998   9998  sexism2022_english-12997   \n",
       "41999   9999  sexism2022_english-12998   \n",
       "\n",
       "                                                    text  annotator  \\\n",
       "0       I wonder what keeps that witch looking quite ...         17   \n",
       "1       I wonder what keeps that witch looking quite ...          2   \n",
       "2      Good for her! My grandson had acid reflux, but...          3   \n",
       "3      The article said Madonna offered to give anyon...          5   \n",
       "4      Gasoline. The answer 60% of America gives when...          8   \n",
       "...                                                  ...        ...   \n",
       "41995  haha woman suck amirite. it's like, obviously ...          1   \n",
       "41996  You mean one that forces women to like wimpy f...          6   \n",
       "41997  You mean one that forces women to like wimpy f...          4   \n",
       "41998  You mean one that forces women to like wimpy f...          2   \n",
       "41999  Gasoline. The answer 60% of America gives when...          9   \n",
       "\n",
       "      label_sexist                            label_category  \\\n",
       "0           sexist                             2. derogation   \n",
       "1           sexist                             2. derogation   \n",
       "2       not sexist                                      none   \n",
       "3           sexist                             2. derogation   \n",
       "4       not sexist                                      none   \n",
       "...            ...                                       ...   \n",
       "41995       sexist                             2. derogation   \n",
       "41996   not sexist                                      none   \n",
       "41997   not sexist                                      none   \n",
       "41998       sexist                              3. animosity   \n",
       "41999       sexist  1. threats, plans to harm and incitement   \n",
       "\n",
       "                                            label_vector  split  \\\n",
       "0                     2.2 aggressive and emotive attacks  train   \n",
       "1                     2.2 aggressive and emotive attacks  train   \n",
       "2                                                   none  train   \n",
       "3      2.3 dehumanising attacks & overt sexual object...  train   \n",
       "4                                                   none  train   \n",
       "...                                                  ...    ...   \n",
       "41995                            2.1 descriptive attacks  train   \n",
       "41996                                               none  train   \n",
       "41997                                               none  train   \n",
       "41998  3.2 immutable gender differences and gender st...  train   \n",
       "41999                                1.1 threats of harm  train   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [i, wonder, what, keep, that, witch, look, qui...  \n",
       "1      [i, wonder, what, keep, that, witch, look, qui...  \n",
       "2      [good, for, her, !, my, grandson, have, acid, ...  \n",
       "3      [the, article, say, madonna, offer, to, give, ...  \n",
       "4      [gasoline, ., the, answer, 60, %, of, america,...  \n",
       "...                                                  ...  \n",
       "41995  [haha, woman, suck, amirite, ., it, be, like, ...  \n",
       "41996  [you, mean, one, that, force, woman, to, like,...  \n",
       "41997  [you, mean, one, that, force, woman, to, like,...  \n",
       "41998  [you, mean, one, that, force, woman, to, like,...  \n",
       "41999  [gasoline, ., the, answer, 60, %, of, america,...  \n",
       "\n",
       "[42000 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the training data\n",
    "tra = load_train().collect()\n",
    "train = tra.to_pandas()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\noika\\Documents\\NLP project\\label_legends\\nlp-ie-label-legends\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12_000, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>text</th><th>tokens</th><th>token_ids</th><th>label</th></tr><tr><td>i64</td><td>str</td><td>list[str]</td><td>list[i64]</td><td>i64</td></tr></thead><tbody><tr><td>100</td><td>&quot;It is not insulting, it&#x27;s **ex…</td><td>[&quot;insulting&quot;, &quot;,&quot;, … &quot;.**&quot;]</td><td>[1407, 22, … 3000]</td><td>1</td></tr><tr><td>10005</td><td>&quot;and if you buy into the Christ…</td><td>[&quot;buy&quot;, &quot;christianity&quot;, … &quot;..&quot;]</td><td>[464, 549, … 27]</td><td>0</td></tr><tr><td>10006</td><td>&quot;and if you buy into the Christ…</td><td>[&quot;buy&quot;, &quot;christianity&quot;, … &quot;..&quot;]</td><td>[464, 549, … 27]</td><td>0</td></tr><tr><td>10007</td><td>&quot;and if you buy into the Christ…</td><td>[&quot;buy&quot;, &quot;christianity&quot;, … &quot;..&quot;]</td><td>[464, 549, … 27]</td><td>0</td></tr><tr><td>10008</td><td>&quot;Given the sub this is posted i…</td><td>[&quot;sub&quot;, &quot;post&quot;, … &quot;shit&quot;]</td><td>[2591, 2042, … 2399]</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>9985</td><td>&quot;Today in leftist violence, Dan…</td><td>[&quot;today&quot;, &quot;leftist&quot;, … &quot;.&quot;]</td><td>[2714, 1553, … 26]</td><td>0</td></tr><tr><td>9986</td><td>&quot;Today in leftist violence, Dan…</td><td>[&quot;today&quot;, &quot;leftist&quot;, … &quot;.&quot;]</td><td>[2714, 1553, … 26]</td><td>0</td></tr><tr><td>9993</td><td>&quot;Shudder.. if you had to have s…</td><td>[&quot;shudder&quot;, &quot;..&quot;, … &quot;.&quot;]</td><td>[3000, 27, … 26]</td><td>1</td></tr><tr><td>9994</td><td>&quot;Shudder.. if you had to have s…</td><td>[&quot;shudder&quot;, &quot;..&quot;, … &quot;.&quot;]</td><td>[3000, 27, … 26]</td><td>0</td></tr><tr><td>9995</td><td>&quot;Shudder.. if you had to have s…</td><td>[&quot;shudder&quot;, &quot;..&quot;, … &quot;.&quot;]</td><td>[3000, 27, … 26]</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12_000, 5)\n",
       "┌───────┬─────────────────────────────┬─────────────────────────────┬──────────────────────┬───────┐\n",
       "│ id    ┆ text                        ┆ tokens                      ┆ token_ids            ┆ label │\n",
       "│ ---   ┆ ---                         ┆ ---                         ┆ ---                  ┆ ---   │\n",
       "│ i64   ┆ str                         ┆ list[str]                   ┆ list[i64]            ┆ i64   │\n",
       "╞═══════╪═════════════════════════════╪═════════════════════════════╪══════════════════════╪═══════╡\n",
       "│ 100   ┆ It is not insulting, it's   ┆ [\"insulting\", \",\", … \".**\"] ┆ [1407, 22, … 3000]   ┆ 1     │\n",
       "│       ┆ **ex…                       ┆                             ┆                      ┆       │\n",
       "│ 10005 ┆ and if you buy into the     ┆ [\"buy\", \"christianity\", …   ┆ [464, 549, … 27]     ┆ 0     │\n",
       "│       ┆ Christ…                     ┆ \"..\"…                       ┆                      ┆       │\n",
       "│ 10006 ┆ and if you buy into the     ┆ [\"buy\", \"christianity\", …   ┆ [464, 549, … 27]     ┆ 0     │\n",
       "│       ┆ Christ…                     ┆ \"..\"…                       ┆                      ┆       │\n",
       "│ 10007 ┆ and if you buy into the     ┆ [\"buy\", \"christianity\", …   ┆ [464, 549, … 27]     ┆ 0     │\n",
       "│       ┆ Christ…                     ┆ \"..\"…                       ┆                      ┆       │\n",
       "│ 10008 ┆ Given the sub this is       ┆ [\"sub\", \"post\", … \"shit\"]   ┆ [2591, 2042, … 2399] ┆ 0     │\n",
       "│       ┆ posted i…                   ┆                             ┆                      ┆       │\n",
       "│ …     ┆ …                           ┆ …                           ┆ …                    ┆ …     │\n",
       "│ 9985  ┆ Today in leftist violence,  ┆ [\"today\", \"leftist\", … \".\"] ┆ [2714, 1553, … 26]   ┆ 0     │\n",
       "│       ┆ Dan…                        ┆                             ┆                      ┆       │\n",
       "│ 9986  ┆ Today in leftist violence,  ┆ [\"today\", \"leftist\", … \".\"] ┆ [2714, 1553, … 26]   ┆ 0     │\n",
       "│       ┆ Dan…                        ┆                             ┆                      ┆       │\n",
       "│ 9993  ┆ Shudder.. if you had to     ┆ [\"shudder\", \"..\", … \".\"]    ┆ [3000, 27, … 26]     ┆ 1     │\n",
       "│       ┆ have s…                     ┆                             ┆                      ┆       │\n",
       "│ 9994  ┆ Shudder.. if you had to     ┆ [\"shudder\", \"..\", … \".\"]    ┆ [3000, 27, … 26]     ┆ 0     │\n",
       "│       ┆ have s…                     ┆                             ┆                      ┆       │\n",
       "│ 9995  ┆ Shudder.. if you had to     ┆ [\"shudder\", \"..\", … \".\"]    ┆ [3000, 27, … 26]     ┆ 1     │\n",
       "│       ┆ have s…                     ┆                             ┆                      ┆       │\n",
       "└───────┴─────────────────────────────┴─────────────────────────────┴──────────────────────┴───────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the test data\n",
    "original = load_test().collect()\n",
    "original = original.drop([\"rewire_id\", \"label_category\",\"label_vector\",\"annotator\"])\n",
    "og_test = transform(original)\n",
    "og_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59996"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(og_test[\"id\"])\n",
    "max(og_test[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_ids</th>\n",
       "      <th>label</th>\n",
       "      <th>model_DeBERTa_pred</th>\n",
       "      <th>model_distilbert_pred</th>\n",
       "      <th>model_mostfrequent_pred</th>\n",
       "      <th>model_Regex_pred</th>\n",
       "      <th>model_xgboost_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>Happy Birthday to your daughter GTR😊</td>\n",
       "      <td>[happy, birthday, daughter, gtr, 😊]</td>\n",
       "      <td>[1238, 363, 747, 3000, 2996]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>Happy Birthday to your daughter GTR😊</td>\n",
       "      <td>[happy, birthday, daughter, gtr, 😊]</td>\n",
       "      <td>[1238, 363, 747, 3000, 2996]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>Happy Birthday to your daughter GTR😊</td>\n",
       "      <td>[happy, birthday, daughter, gtr, 😊]</td>\n",
       "      <td>[1238, 363, 747, 3000, 2996]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>NEGRO Baltimore mayor and NEGRO police commiss...</td>\n",
       "      <td>[negro, baltimore, mayor, negro, police, commi...</td>\n",
       "      <td>[1823, 3000, 1680, 1823, 2022, 3000, 3000, 182...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>NEGRO Baltimore mayor and NEGRO police commiss...</td>\n",
       "      <td>[negro, baltimore, mayor, negro, police, commi...</td>\n",
       "      <td>[1823, 3000, 1680, 1823, 2022, 3000, 3000, 182...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>59992</td>\n",
       "      <td>You can stop right there asshole, she is a mar...</td>\n",
       "      <td>[stop, right, asshole, ,, married, woman, fami...</td>\n",
       "      <td>[2567, 2274, 257, 22, 1661, 2937, 1020, 26]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>59993</td>\n",
       "      <td>You can stop right there asshole, she is a mar...</td>\n",
       "      <td>[stop, right, asshole, ,, married, woman, fami...</td>\n",
       "      <td>[2567, 2274, 257, 22, 1661, 2937, 1020, 26]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>59994</td>\n",
       "      <td>Since 1973, America has sanctioned the murder ...</td>\n",
       "      <td>[1973, ,, america, sanction, murder, 58, milli...</td>\n",
       "      <td>[3000, 22, 195, 3000, 1782, 3000, 1722, 536, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>59995</td>\n",
       "      <td>Since 1973, America has sanctioned the murder ...</td>\n",
       "      <td>[1973, ,, america, sanction, murder, 58, milli...</td>\n",
       "      <td>[3000, 22, 195, 3000, 1782, 3000, 1722, 536, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>59996</td>\n",
       "      <td>Since 1973, America has sanctioned the murder ...</td>\n",
       "      <td>[1973, ,, america, sanction, murder, 58, milli...</td>\n",
       "      <td>[3000, 22, 195, 3000, 1782, 3000, 1722, 536, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  \\\n",
       "0         27               Happy Birthday to your daughter GTR😊   \n",
       "1         28               Happy Birthday to your daughter GTR😊   \n",
       "2         29               Happy Birthday to your daughter GTR😊   \n",
       "3         30  NEGRO Baltimore mayor and NEGRO police commiss...   \n",
       "4         31  NEGRO Baltimore mayor and NEGRO police commiss...   \n",
       "...      ...                                                ...   \n",
       "11995  59992  You can stop right there asshole, she is a mar...   \n",
       "11996  59993  You can stop right there asshole, she is a mar...   \n",
       "11997  59994  Since 1973, America has sanctioned the murder ...   \n",
       "11998  59995  Since 1973, America has sanctioned the murder ...   \n",
       "11999  59996  Since 1973, America has sanctioned the murder ...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0                    [happy, birthday, daughter, gtr, 😊]   \n",
       "1                    [happy, birthday, daughter, gtr, 😊]   \n",
       "2                    [happy, birthday, daughter, gtr, 😊]   \n",
       "3      [negro, baltimore, mayor, negro, police, commi...   \n",
       "4      [negro, baltimore, mayor, negro, police, commi...   \n",
       "...                                                  ...   \n",
       "11995  [stop, right, asshole, ,, married, woman, fami...   \n",
       "11996  [stop, right, asshole, ,, married, woman, fami...   \n",
       "11997  [1973, ,, america, sanction, murder, 58, milli...   \n",
       "11998  [1973, ,, america, sanction, murder, 58, milli...   \n",
       "11999  [1973, ,, america, sanction, murder, 58, milli...   \n",
       "\n",
       "                                               token_ids  label  \\\n",
       "0                           [1238, 363, 747, 3000, 2996]      0   \n",
       "1                           [1238, 363, 747, 3000, 2996]      0   \n",
       "2                           [1238, 363, 747, 3000, 2996]      0   \n",
       "3      [1823, 3000, 1680, 1823, 2022, 3000, 3000, 182...      0   \n",
       "4      [1823, 3000, 1680, 1823, 2022, 3000, 3000, 182...      0   \n",
       "...                                                  ...    ...   \n",
       "11995        [2567, 2274, 257, 22, 1661, 2937, 1020, 26]      0   \n",
       "11996        [2567, 2274, 257, 22, 1661, 2937, 1020, 26]      0   \n",
       "11997  [3000, 22, 195, 3000, 1782, 3000, 1722, 536, 1...      1   \n",
       "11998  [3000, 22, 195, 3000, 1782, 3000, 1722, 536, 1...      1   \n",
       "11999  [3000, 22, 195, 3000, 1782, 3000, 1722, 536, 1...      0   \n",
       "\n",
       "       model_DeBERTa_pred  model_distilbert_pred  model_mostfrequent_pred  \\\n",
       "0                       0                      0                        0   \n",
       "1                       0                      0                        0   \n",
       "2                       0                      0                        0   \n",
       "3                       0                      0                        0   \n",
       "4                       0                      0                        0   \n",
       "...                   ...                    ...                      ...   \n",
       "11995                   0                      0                        0   \n",
       "11996                   0                      0                        0   \n",
       "11997                   0                      0                        0   \n",
       "11998                   0                      0                        0   \n",
       "11999                   0                      0                        0   \n",
       "\n",
       "       model_Regex_pred  model_xgboost_pred  \n",
       "0                     0                   0  \n",
       "1                     0                   0  \n",
       "2                     0                   0  \n",
       "3                     1                   0  \n",
       "4                     1                   0  \n",
       "...                 ...                 ...  \n",
       "11995                 1                   0  \n",
       "11996                 1                   0  \n",
       "11997                 1                   0  \n",
       "11998                 1                   0  \n",
       "11999                 1                   0  \n",
       "\n",
       "[12000 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_folder = r\"../resource/mlflow\"\n",
    "\n",
    "final_df = None\n",
    "\n",
    "for dir in os.listdir(main_folder):\n",
    "    path = os.path.join(main_folder, dir)\n",
    "\n",
    "    if os.path.isdir(path):\n",
    "        #get the final path to the json file\n",
    "        json_file_path = os.path.join(path, \"predictions.json\")\n",
    "\n",
    "        #loading the json file\n",
    "        if os.path.exists(json_file_path):\n",
    "            with open(json_file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            df = pd.DataFrame(data[\"data\"], columns=[\"id\", f\"model_{dir}_pred\"])\n",
    "\n",
    "            #merge the dataframes\n",
    "            if final_df is None:\n",
    "                final_df = df\n",
    "            else:\n",
    "                final_df = pd.merge(final_df, df, on=\"id\", how=\"outer\")\n",
    "\n",
    "#merge the predictions to the test data to get a dataset with the true label and the predictions\n",
    "og_test = og_test.to_pandas()\n",
    "final_df = pd.merge(og_test, final_df, on=\"id\", how=\"outer\")\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning an error level to every row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error level shows how many of our model got the label wrong. If all 5 models predicted wrong, the error level is 5, in case every model predicted right, the error level is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_ids</th>\n",
       "      <th>label</th>\n",
       "      <th>model_DeBERTa_pred</th>\n",
       "      <th>model_distilbert_pred</th>\n",
       "      <th>model_mostfrequent_pred</th>\n",
       "      <th>model_Regex_pred</th>\n",
       "      <th>model_xgboost_pred</th>\n",
       "      <th>error_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11958</th>\n",
       "      <td>59787</td>\n",
       "      <td>Don’t misunderstand me, I love my mother to de...</td>\n",
       "      <td>[misunderstand, ,, love, mother, death, ., tim...</td>\n",
       "      <td>[3000, 22, 1616, 1764, 755, 26, 2707, 22, 1579...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>6660</td>\n",
       "      <td>gagging test (pay no attention to the caterpil...</td>\n",
       "      <td>[gagge, test, (, pay, attention, caterpillar, ...</td>\n",
       "      <td>[3000, 2673, 16, 1949, 266, 3000, 999, 17]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11122</th>\n",
       "      <td>55483</td>\n",
       "      <td>Yeah I've never seen a black women that even c...</td>\n",
       "      <td>[yeah, black, woman, compare, dana, .]</td>\n",
       "      <td>[2966, 369, 2937, 612, 3000, 26]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11984</th>\n",
       "      <td>59951</td>\n",
       "      <td>NOT MY PROBLEM LOL I doubt it is as bad as rep...</td>\n",
       "      <td>[problem, lol, doubt, bad, reput, ..., know, i...</td>\n",
       "      <td>[2090, 1602, 859, 297, 3000, 28, 1511, 1434, 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11028</th>\n",
       "      <td>54948</td>\n",
       "      <td>Also 35. I had no idea. I thought young girls ...</td>\n",
       "      <td>[35, ., idea, ., think, young, girl, like, guy...</td>\n",
       "      <td>[69, 26, 1336, 26, 2688, 2975, 1164, 1579, 121...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>36347</td>\n",
       "      <td>Could we not diffuse the entire \"this hurt's t...</td>\n",
       "      <td>[diffuse, entire, \", hurt, poor, \", argument, ...</td>\n",
       "      <td>[3000, 938, 6, 1328, 2029, 6, 236, 2871, 1335,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300</th>\n",
       "      <td>36346</td>\n",
       "      <td>Could we not diffuse the entire \"this hurt's t...</td>\n",
       "      <td>[diffuse, entire, \", hurt, poor, \", argument, ...</td>\n",
       "      <td>[3000, 938, 6, 1328, 2029, 6, 236, 2871, 1335,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>36345</td>\n",
       "      <td>Could we not diffuse the entire \"this hurt's t...</td>\n",
       "      <td>[diffuse, entire, \", hurt, poor, \", argument, ...</td>\n",
       "      <td>[3000, 938, 6, 1328, 2029, 6, 236, 2871, 1335,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7313</th>\n",
       "      <td>36431</td>\n",
       "      <td>Do your daughters need hot 'n' heavy hands-on ...</td>\n",
       "      <td>[daughter, need, hot, ', ', heavy, hand, -, \",...</td>\n",
       "      <td>[747, 1820, 1314, 13, 13, 1261, 1230, 23, 6, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7312</th>\n",
       "      <td>36430</td>\n",
       "      <td>Do your daughters need hot 'n' heavy hands-on ...</td>\n",
       "      <td>[daughter, need, hot, ', ', heavy, hand, -, \",...</td>\n",
       "      <td>[747, 1820, 1314, 13, 13, 1261, 1230, 23, 6, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  \\\n",
       "11958  59787  Don’t misunderstand me, I love my mother to de...   \n",
       "1335    6660  gagging test (pay no attention to the caterpil...   \n",
       "11122  55483  Yeah I've never seen a black women that even c...   \n",
       "11984  59951  NOT MY PROBLEM LOL I doubt it is as bad as rep...   \n",
       "11028  54948  Also 35. I had no idea. I thought young girls ...   \n",
       "...      ...                                                ...   \n",
       "7301   36347  Could we not diffuse the entire \"this hurt's t...   \n",
       "7300   36346  Could we not diffuse the entire \"this hurt's t...   \n",
       "7299   36345  Could we not diffuse the entire \"this hurt's t...   \n",
       "7313   36431  Do your daughters need hot 'n' heavy hands-on ...   \n",
       "7312   36430  Do your daughters need hot 'n' heavy hands-on ...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "11958  [misunderstand, ,, love, mother, death, ., tim...   \n",
       "1335   [gagge, test, (, pay, attention, caterpillar, ...   \n",
       "11122             [yeah, black, woman, compare, dana, .]   \n",
       "11984  [problem, lol, doubt, bad, reput, ..., know, i...   \n",
       "11028  [35, ., idea, ., think, young, girl, like, guy...   \n",
       "...                                                  ...   \n",
       "7301   [diffuse, entire, \", hurt, poor, \", argument, ...   \n",
       "7300   [diffuse, entire, \", hurt, poor, \", argument, ...   \n",
       "7299   [diffuse, entire, \", hurt, poor, \", argument, ...   \n",
       "7313   [daughter, need, hot, ', ', heavy, hand, -, \",...   \n",
       "7312   [daughter, need, hot, ', ', heavy, hand, -, \",...   \n",
       "\n",
       "                                               token_ids  label  \\\n",
       "11958  [3000, 22, 1616, 1764, 755, 26, 2707, 22, 1579...      1   \n",
       "1335          [3000, 2673, 16, 1949, 266, 3000, 999, 17]      1   \n",
       "11122                   [2966, 369, 2937, 612, 3000, 26]      1   \n",
       "11984  [2090, 1602, 859, 297, 3000, 28, 1511, 1434, 2...      1   \n",
       "11028  [69, 26, 1336, 26, 2688, 2975, 1164, 1579, 121...      1   \n",
       "...                                                  ...    ...   \n",
       "7301   [3000, 938, 6, 1328, 2029, 6, 236, 2871, 1335,...      0   \n",
       "7300   [3000, 938, 6, 1328, 2029, 6, 236, 2871, 1335,...      0   \n",
       "7299   [3000, 938, 6, 1328, 2029, 6, 236, 2871, 1335,...      0   \n",
       "7313   [747, 1820, 1314, 13, 13, 1261, 1230, 23, 6, 2...      0   \n",
       "7312   [747, 1820, 1314, 13, 13, 1261, 1230, 23, 6, 2...      0   \n",
       "\n",
       "       model_DeBERTa_pred  model_distilbert_pred  model_mostfrequent_pred  \\\n",
       "11958                   0                      0                        0   \n",
       "1335                    0                      0                        0   \n",
       "11122                   0                      0                        0   \n",
       "11984                   0                      0                        0   \n",
       "11028                   0                      0                        0   \n",
       "...                   ...                    ...                      ...   \n",
       "7301                    0                      0                        0   \n",
       "7300                    0                      0                        0   \n",
       "7299                    0                      0                        0   \n",
       "7313                    0                      0                        0   \n",
       "7312                    0                      0                        0   \n",
       "\n",
       "       model_Regex_pred  model_xgboost_pred  error_level  \n",
       "11958                 0                   0            5  \n",
       "1335                  0                   0            5  \n",
       "11122                 0                   0            5  \n",
       "11984                 0                   0            5  \n",
       "11028                 0                   0            5  \n",
       "...                 ...                 ...          ...  \n",
       "7301                  0                   0            0  \n",
       "7300                  0                   0            0  \n",
       "7299                  0                   0            0  \n",
       "7313                  0                   0            0  \n",
       "7312                  0                   0            0  \n",
       "\n",
       "[12000 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating the error level\n",
    "final_df[\"error_level\"] = 5\n",
    "\n",
    "for i, row in final_df.iterrows():\n",
    "    true_label = row[\"label\"]\n",
    "    true_label_count = 0\n",
    "    for column in final_df.columns:\n",
    "        if \"model\" in column:\n",
    "            pred_label = row[column]\n",
    "            if pred_label == true_label:\n",
    "                true_label_count += 1\n",
    "    final_df.at[i,\"error_level\"] = 5 - true_label_count\n",
    "\n",
    "final_df = final_df.sort_values(by=\"error_level\", ascending=False)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error level 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: how many times got all of the models the predictions wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_ids</th>\n",
       "      <th>label</th>\n",
       "      <th>model_DeBERTa_pred</th>\n",
       "      <th>model_distilbert_pred</th>\n",
       "      <th>model_mostfrequent_pred</th>\n",
       "      <th>model_Regex_pred</th>\n",
       "      <th>model_xgboost_pred</th>\n",
       "      <th>error_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11958</th>\n",
       "      <td>59787</td>\n",
       "      <td>Don’t misunderstand me, I love my mother to de...</td>\n",
       "      <td>[misunderstand, ,, love, mother, death, ., tim...</td>\n",
       "      <td>[3000, 22, 1616, 1764, 755, 26, 2707, 22, 1579...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>6660</td>\n",
       "      <td>gagging test (pay no attention to the caterpil...</td>\n",
       "      <td>[gagge, test, (, pay, attention, caterpillar, ...</td>\n",
       "      <td>[3000, 2673, 16, 1949, 266, 3000, 999, 17]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11122</th>\n",
       "      <td>55483</td>\n",
       "      <td>Yeah I've never seen a black women that even c...</td>\n",
       "      <td>[yeah, black, woman, compare, dana, .]</td>\n",
       "      <td>[2966, 369, 2937, 612, 3000, 26]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11984</th>\n",
       "      <td>59951</td>\n",
       "      <td>NOT MY PROBLEM LOL I doubt it is as bad as rep...</td>\n",
       "      <td>[problem, lol, doubt, bad, reput, ..., know, i...</td>\n",
       "      <td>[2090, 1602, 859, 297, 3000, 28, 1511, 1434, 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11028</th>\n",
       "      <td>54948</td>\n",
       "      <td>Also 35. I had no idea. I thought young girls ...</td>\n",
       "      <td>[35, ., idea, ., think, young, girl, like, guy...</td>\n",
       "      <td>[69, 26, 1336, 26, 2688, 2975, 1164, 1579, 121...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>6927</td>\n",
       "      <td>Gorier Allred is a blatant misandrist. Her dad...</td>\n",
       "      <td>[gorier, allred, blatant, misandrist, ., dad, ...</td>\n",
       "      <td>[3000, 3000, 3000, 3000, 26, 730, 1749, 26]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>6928</td>\n",
       "      <td>Gorier Allred is a blatant misandrist. Her dad...</td>\n",
       "      <td>[gorier, allred, blatant, misandrist, ., dad, ...</td>\n",
       "      <td>[3000, 3000, 3000, 3000, 26, 730, 1749, 26]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100</th>\n",
       "      <td>55437</td>\n",
       "      <td>Yeah right 🤣🤣🤣. Guys who keep female friends a...</td>\n",
       "      <td>[yeah, right, 🤣🤣🤣, ., guy, female, friend, guy...</td>\n",
       "      <td>[2966, 2274, 3000, 26, 1215, 1047, 1113, 1215,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11975</th>\n",
       "      <td>59894</td>\n",
       "      <td>The next person to play James Bond will be fem...</td>\n",
       "      <td>[person, play, james, bond, female, ., watch, ...</td>\n",
       "      <td>[1973, 2012, 1450, 387, 1047, 26, 2887, 1235, 26]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11982</th>\n",
       "      <td>59949</td>\n",
       "      <td>NOT MY PROBLEM LOL I doubt it is as bad as rep...</td>\n",
       "      <td>[problem, lol, doubt, bad, reput, ..., know, i...</td>\n",
       "      <td>[2090, 1602, 859, 297, 3000, 28, 1511, 1434, 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>474 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  \\\n",
       "11958  59787  Don’t misunderstand me, I love my mother to de...   \n",
       "1335    6660  gagging test (pay no attention to the caterpil...   \n",
       "11122  55483  Yeah I've never seen a black women that even c...   \n",
       "11984  59951  NOT MY PROBLEM LOL I doubt it is as bad as rep...   \n",
       "11028  54948  Also 35. I had no idea. I thought young girls ...   \n",
       "...      ...                                                ...   \n",
       "1377    6927  Gorier Allred is a blatant misandrist. Her dad...   \n",
       "1378    6928  Gorier Allred is a blatant misandrist. Her dad...   \n",
       "11100  55437  Yeah right 🤣🤣🤣. Guys who keep female friends a...   \n",
       "11975  59894  The next person to play James Bond will be fem...   \n",
       "11982  59949  NOT MY PROBLEM LOL I doubt it is as bad as rep...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "11958  [misunderstand, ,, love, mother, death, ., tim...   \n",
       "1335   [gagge, test, (, pay, attention, caterpillar, ...   \n",
       "11122             [yeah, black, woman, compare, dana, .]   \n",
       "11984  [problem, lol, doubt, bad, reput, ..., know, i...   \n",
       "11028  [35, ., idea, ., think, young, girl, like, guy...   \n",
       "...                                                  ...   \n",
       "1377   [gorier, allred, blatant, misandrist, ., dad, ...   \n",
       "1378   [gorier, allred, blatant, misandrist, ., dad, ...   \n",
       "11100  [yeah, right, 🤣🤣🤣, ., guy, female, friend, guy...   \n",
       "11975  [person, play, james, bond, female, ., watch, ...   \n",
       "11982  [problem, lol, doubt, bad, reput, ..., know, i...   \n",
       "\n",
       "                                               token_ids  label  \\\n",
       "11958  [3000, 22, 1616, 1764, 755, 26, 2707, 22, 1579...      1   \n",
       "1335          [3000, 2673, 16, 1949, 266, 3000, 999, 17]      1   \n",
       "11122                   [2966, 369, 2937, 612, 3000, 26]      1   \n",
       "11984  [2090, 1602, 859, 297, 3000, 28, 1511, 1434, 2...      1   \n",
       "11028  [69, 26, 1336, 26, 2688, 2975, 1164, 1579, 121...      1   \n",
       "...                                                  ...    ...   \n",
       "1377         [3000, 3000, 3000, 3000, 26, 730, 1749, 26]      1   \n",
       "1378         [3000, 3000, 3000, 3000, 26, 730, 1749, 26]      1   \n",
       "11100  [2966, 2274, 3000, 26, 1215, 1047, 1113, 1215,...      1   \n",
       "11975  [1973, 2012, 1450, 387, 1047, 26, 2887, 1235, 26]      1   \n",
       "11982  [2090, 1602, 859, 297, 3000, 28, 1511, 1434, 2...      1   \n",
       "\n",
       "       model_DeBERTa_pred  model_distilbert_pred  model_mostfrequent_pred  \\\n",
       "11958                   0                      0                        0   \n",
       "1335                    0                      0                        0   \n",
       "11122                   0                      0                        0   \n",
       "11984                   0                      0                        0   \n",
       "11028                   0                      0                        0   \n",
       "...                   ...                    ...                      ...   \n",
       "1377                    0                      0                        0   \n",
       "1378                    0                      0                        0   \n",
       "11100                   0                      0                        0   \n",
       "11975                   0                      0                        0   \n",
       "11982                   0                      0                        0   \n",
       "\n",
       "       model_Regex_pred  model_xgboost_pred  error_level  \n",
       "11958                 0                   0            5  \n",
       "1335                  0                   0            5  \n",
       "11122                 0                   0            5  \n",
       "11984                 0                   0            5  \n",
       "11028                 0                   0            5  \n",
       "...                 ...                 ...          ...  \n",
       "1377                  0                   0            5  \n",
       "1378                  0                   0            5  \n",
       "11100                 0                   0            5  \n",
       "11975                 0                   0            5  \n",
       "11982                 0                   0            5  \n",
       "\n",
       "[474 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_df = final_df[final_df['error_level'] == 5]\n",
    "display(error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All five models got the predictions wrong 474 times.\n"
     ]
    }
   ],
   "source": [
    "n_error_5 = error_df.shape[0]\n",
    "print(f\"All five models got the predictions wrong {n_error_5} times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error level 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: how many times got every model the prediction right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_error_df = final_df[final_df['error_level'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All five models got the predictions right 4659 times.\n"
     ]
    }
   ],
   "source": [
    "n_error_0 = no_error_df.shape[0]\n",
    "print(f\"All five models got the predictions right {n_error_0} times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification error insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see how many tokens are missing from the training dataset that are in the list of tokens where the models got the predictions wrong. We think that missing tokens from the training dataset could also lead to errors in the classification on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13485342019543975"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens = set(token for tokens in train[\"tokens\"] for token in tokens)\n",
    "\n",
    "# Flatten and get unique tokens from the test dataset\n",
    "test_tokens = set(token for tokens in final_df[\"tokens\"] for token in tokens)\n",
    "\n",
    "error_tokens = set(token for tokens in error_df[\"tokens\"] for token in tokens)\n",
    "\n",
    "# Find tokens in the test dataset that are not in the train dataset\n",
    "missing_tokens = test_tokens - train_tokens\n",
    "len(missing_tokens)\n",
    "\n",
    "error_in_missing = error_tokens.intersection(missing_tokens)\n",
    "error_token_rate = len(error_in_missing) / len(error_tokens) if len(error_tokens) > 0 else 0\n",
    "error_token_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also calculate how many times each token appears in the wrongly classified tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      token  count\n",
      "5         .    621\n",
      "1         ,    333\n",
      "21    woman    165\n",
      "43        ?     84\n",
      "143     man     67\n",
      "346       \"     66\n",
      "39     girl     65\n",
      "7      like     55\n",
      "54     just     54\n",
      "29      ...     54\n",
      "169     say     39\n",
      "171       -     39\n",
      "215    good     35\n",
      "18        )     34\n",
      "209    look     34\n",
      "155       !     33\n",
      "542  female     33\n",
      "258       #     31\n",
      "497       :     31\n",
      "37    think     30\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#list of all the token in error_df\n",
    "all_tokens = [token for tokens in error_df['tokens'] for token in tokens]\n",
    "\n",
    "#count each token in the list\n",
    "token_counts = Counter(all_tokens)\n",
    "\n",
    "#sort the dataframe\n",
    "token_count_df = pd.DataFrame(token_counts.items(), columns=['token', 'count'])\n",
    "token_count_df = token_count_df.sort_values(by='count', ascending=False)\n",
    "\n",
    "print(token_count_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words pointing to the female sex are 3 out of the top 20: woman, girll, female. Our suspition is that the models cannot get the stereotypes or sarcasm right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error levels 4 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_ids</th>\n",
       "      <th>label</th>\n",
       "      <th>model_DeBERTa_pred</th>\n",
       "      <th>model_distilbert_pred</th>\n",
       "      <th>model_mostfrequent_pred</th>\n",
       "      <th>model_Regex_pred</th>\n",
       "      <th>model_xgboost_pred</th>\n",
       "      <th>error_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11958</th>\n",
       "      <td>59787</td>\n",
       "      <td>Don’t misunderstand me, I love my mother to de...</td>\n",
       "      <td>[misunderstand, ,, love, mother, death, ., tim...</td>\n",
       "      <td>[3000, 22, 1616, 1764, 755, 26, 2707, 22, 1579...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>6660</td>\n",
       "      <td>gagging test (pay no attention to the caterpil...</td>\n",
       "      <td>[gagge, test, (, pay, attention, caterpillar, ...</td>\n",
       "      <td>[3000, 2673, 16, 1949, 266, 3000, 999, 17]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11122</th>\n",
       "      <td>55483</td>\n",
       "      <td>Yeah I've never seen a black women that even c...</td>\n",
       "      <td>[yeah, black, woman, compare, dana, .]</td>\n",
       "      <td>[2966, 369, 2937, 612, 3000, 26]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11984</th>\n",
       "      <td>59951</td>\n",
       "      <td>NOT MY PROBLEM LOL I doubt it is as bad as rep...</td>\n",
       "      <td>[problem, lol, doubt, bad, reput, ..., know, i...</td>\n",
       "      <td>[2090, 1602, 859, 297, 3000, 28, 1511, 1434, 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11028</th>\n",
       "      <td>54948</td>\n",
       "      <td>Also 35. I had no idea. I thought young girls ...</td>\n",
       "      <td>[35, ., idea, ., think, young, girl, like, guy...</td>\n",
       "      <td>[69, 26, 1336, 26, 2688, 2975, 1164, 1579, 121...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7250</th>\n",
       "      <td>36113</td>\n",
       "      <td>Poisoned drinks fall under the category of \"re...</td>\n",
       "      <td>[poison, drink, fall, category, \", real, rape,...</td>\n",
       "      <td>[3000, 872, 1015, 3000, 6, 2188, 2174, 6, 16, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>36784</td>\n",
       "      <td>I see. I hope that your balls are metaphorical...</td>\n",
       "      <td>[., hope, ball, metaphorical, ,, little, lady, .]</td>\n",
       "      <td>[26, 1305, 303, 3000, 22, 1589, 1520, 26]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>36785</td>\n",
       "      <td>I see. I hope that your balls are metaphorical...</td>\n",
       "      <td>[., hope, ball, metaphorical, ,, little, lady, .]</td>\n",
       "      <td>[26, 1305, 303, 3000, 22, 1589, 1520, 26]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>6753</td>\n",
       "      <td>Why do all these commie girls have middle age ...</td>\n",
       "      <td>[commie, girl, middle, age, belly, ?]</td>\n",
       "      <td>[603, 1164, 1716, 164, 3000, 98]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11146</th>\n",
       "      <td>55546</td>\n",
       "      <td>I don’t know who that is, but sounds like she ...</td>\n",
       "      <td>[know, ,, sound, like, load, yeah, fuck, ., 9,...</td>\n",
       "      <td>[1511, 22, 2502, 1579, 1595, 2966, 1118, 26, 8...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1269 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  \\\n",
       "11958  59787  Don’t misunderstand me, I love my mother to de...   \n",
       "1335    6660  gagging test (pay no attention to the caterpil...   \n",
       "11122  55483  Yeah I've never seen a black women that even c...   \n",
       "11984  59951  NOT MY PROBLEM LOL I doubt it is as bad as rep...   \n",
       "11028  54948  Also 35. I had no idea. I thought young girls ...   \n",
       "...      ...                                                ...   \n",
       "7250   36113  Poisoned drinks fall under the category of \"re...   \n",
       "7390   36784  I see. I hope that your balls are metaphorical...   \n",
       "7391   36785  I see. I hope that your balls are metaphorical...   \n",
       "1353    6753  Why do all these commie girls have middle age ...   \n",
       "11146  55546  I don’t know who that is, but sounds like she ...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "11958  [misunderstand, ,, love, mother, death, ., tim...   \n",
       "1335   [gagge, test, (, pay, attention, caterpillar, ...   \n",
       "11122             [yeah, black, woman, compare, dana, .]   \n",
       "11984  [problem, lol, doubt, bad, reput, ..., know, i...   \n",
       "11028  [35, ., idea, ., think, young, girl, like, guy...   \n",
       "...                                                  ...   \n",
       "7250   [poison, drink, fall, category, \", real, rape,...   \n",
       "7390   [., hope, ball, metaphorical, ,, little, lady, .]   \n",
       "7391   [., hope, ball, metaphorical, ,, little, lady, .]   \n",
       "1353               [commie, girl, middle, age, belly, ?]   \n",
       "11146  [know, ,, sound, like, load, yeah, fuck, ., 9,...   \n",
       "\n",
       "                                               token_ids  label  \\\n",
       "11958  [3000, 22, 1616, 1764, 755, 26, 2707, 22, 1579...      1   \n",
       "1335          [3000, 2673, 16, 1949, 266, 3000, 999, 17]      1   \n",
       "11122                   [2966, 369, 2937, 612, 3000, 26]      1   \n",
       "11984  [2090, 1602, 859, 297, 3000, 28, 1511, 1434, 2...      1   \n",
       "11028  [69, 26, 1336, 26, 2688, 2975, 1164, 1579, 121...      1   \n",
       "...                                                  ...    ...   \n",
       "7250   [3000, 872, 1015, 3000, 6, 2188, 2174, 6, 16, ...      1   \n",
       "7390           [26, 1305, 303, 3000, 22, 1589, 1520, 26]      1   \n",
       "7391           [26, 1305, 303, 3000, 22, 1589, 1520, 26]      1   \n",
       "1353                    [603, 1164, 1716, 164, 3000, 98]      1   \n",
       "11146  [1511, 22, 2502, 1579, 1595, 2966, 1118, 26, 8...      1   \n",
       "\n",
       "       model_DeBERTa_pred  model_distilbert_pred  model_mostfrequent_pred  \\\n",
       "11958                   0                      0                        0   \n",
       "1335                    0                      0                        0   \n",
       "11122                   0                      0                        0   \n",
       "11984                   0                      0                        0   \n",
       "11028                   0                      0                        0   \n",
       "...                   ...                    ...                      ...   \n",
       "7250                    0                      0                        0   \n",
       "7390                    0                      0                        0   \n",
       "7391                    0                      0                        0   \n",
       "1353                    0                      0                        0   \n",
       "11146                   0                      0                        0   \n",
       "\n",
       "       model_Regex_pred  model_xgboost_pred  error_level  \n",
       "11958                 0                   0            5  \n",
       "1335                  0                   0            5  \n",
       "11122                 0                   0            5  \n",
       "11984                 0                   0            5  \n",
       "11028                 0                   0            5  \n",
       "...                 ...                 ...          ...  \n",
       "7250                  1                   0            4  \n",
       "7390                  1                   0            4  \n",
       "7391                  1                   0            4  \n",
       "1353                  1                   0            4  \n",
       "11146                 1                   0            4  \n",
       "\n",
       "[1269 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "high_error_df = final_df[final_df['error_level'] > 3]\n",
    "display(high_error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rate of how many token were not in the training tokens from the misclassified ones: 0.1645933014354067\n"
     ]
    }
   ],
   "source": [
    "high_error_tokens = set(token for tokens in high_error_df[\"tokens\"] for token in tokens)\n",
    "\n",
    "# Find tokens in the test dataset that are not in the train dataset\n",
    "missing_tokens = test_tokens - train_tokens\n",
    "len(missing_tokens)\n",
    "\n",
    "high_error_in_missing = high_error_tokens.intersection(missing_tokens)\n",
    "high_error_token_rate = len(high_error_in_missing) / len(high_error_tokens) if len(high_error_tokens) > 0 else 0\n",
    "print(f\"The rate of how many token were not in the training tokens from the misclassified ones: {high_error_token_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       token  count\n",
      "5          .   1816\n",
      "1          ,    994\n",
      "21     woman    519\n",
      "346        \"    265\n",
      "43         ?    233\n",
      "39      girl    181\n",
      "7       like    179\n",
      "143      man    175\n",
      "54      just    145\n",
      "171        -    118\n",
      "169      say    107\n",
      "29       ...    105\n",
      "1570    fuck    100\n",
      "30      know     97\n",
      "215     good     97\n",
      "155        !     95\n",
      "89      want     89\n",
      "40       guy     85\n",
      "542   female     84\n",
      "209     look     83\n"
     ]
    }
   ],
   "source": [
    "all_tokens_high = [token for tokens in high_error_df['tokens'] for token in tokens]\n",
    "\n",
    "#count each token in the list\n",
    "high_token_counts = Counter(all_tokens_high)\n",
    "\n",
    "#sort the dataframe\n",
    "high_token_count_df = pd.DataFrame(high_token_counts.items(), columns=['token', 'count'])\n",
    "high_token_count_df = high_token_count_df.sort_values(by='count', ascending=False)\n",
    "\n",
    "print(high_token_count_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the texts from error levels 4 and 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are saving the texts where most of our models (4 or 5) predicted wrong in order to inspect them a little closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_error_texts = pd.DataFrame(high_error_df, columns=[\"text\"])\n",
    "high_error_texts.drop_duplicates(inplace=True)\n",
    "high_error_texts.to_csv(r\"../resource/high_error_texts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>error_level</th>\n",
       "      <th>token_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11958</th>\n",
       "      <td>59787</td>\n",
       "      <td>Don’t misunderstand me, I love my mother to de...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'misunderstand': 1, ',': 2, 'love': 1, 'mothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>6660</td>\n",
       "      <td>gagging test (pay no attention to the caterpil...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'gagge': 1, 'test': 1, '(': 1, 'pay': 1, 'att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11122</th>\n",
       "      <td>55483</td>\n",
       "      <td>Yeah I've never seen a black women that even c...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'yeah': 1, 'black': 1, 'woman': 1, 'compare':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11984</th>\n",
       "      <td>59951</td>\n",
       "      <td>NOT MY PROBLEM LOL I doubt it is as bad as rep...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'problem': 1, 'lol': 1, 'doubt': 1, 'bad': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11028</th>\n",
       "      <td>54948</td>\n",
       "      <td>Also 35. I had no idea. I thought young girls ...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'35': 1, '.': 3, 'idea': 1, 'think': 1, 'youn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>36347</td>\n",
       "      <td>Could we not diffuse the entire \"this hurt's t...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'diffuse': 1, 'entire': 1, '\"': 2, 'hurt': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300</th>\n",
       "      <td>36346</td>\n",
       "      <td>Could we not diffuse the entire \"this hurt's t...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'diffuse': 1, 'entire': 1, '\"': 2, 'hurt': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>36345</td>\n",
       "      <td>Could we not diffuse the entire \"this hurt's t...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'diffuse': 1, 'entire': 1, '\"': 2, 'hurt': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7313</th>\n",
       "      <td>36431</td>\n",
       "      <td>Do your daughters need hot 'n' heavy hands-on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'daughter': 1, 'need': 1, 'hot': 1, ''': 2, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7312</th>\n",
       "      <td>36430</td>\n",
       "      <td>Do your daughters need hot 'n' heavy hands-on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'daughter': 1, 'need': 1, 'hot': 1, ''': 2, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  error_level  \\\n",
       "11958  59787  Don’t misunderstand me, I love my mother to de...            5   \n",
       "1335    6660  gagging test (pay no attention to the caterpil...            5   \n",
       "11122  55483  Yeah I've never seen a black women that even c...            5   \n",
       "11984  59951  NOT MY PROBLEM LOL I doubt it is as bad as rep...            5   \n",
       "11028  54948  Also 35. I had no idea. I thought young girls ...            5   \n",
       "...      ...                                                ...          ...   \n",
       "7301   36347  Could we not diffuse the entire \"this hurt's t...            0   \n",
       "7300   36346  Could we not diffuse the entire \"this hurt's t...            0   \n",
       "7299   36345  Could we not diffuse the entire \"this hurt's t...            0   \n",
       "7313   36431  Do your daughters need hot 'n' heavy hands-on ...            0   \n",
       "7312   36430  Do your daughters need hot 'n' heavy hands-on ...            0   \n",
       "\n",
       "                                            token_counts  \n",
       "11958  {'misunderstand': 1, ',': 2, 'love': 1, 'mothe...  \n",
       "1335   {'gagge': 1, 'test': 1, '(': 1, 'pay': 1, 'att...  \n",
       "11122  {'yeah': 1, 'black': 1, 'woman': 1, 'compare':...  \n",
       "11984  {'problem': 1, 'lol': 1, 'doubt': 1, 'bad': 1,...  \n",
       "11028  {'35': 1, '.': 3, 'idea': 1, 'think': 1, 'youn...  \n",
       "...                                                  ...  \n",
       "7301   {'diffuse': 1, 'entire': 1, '\"': 2, 'hurt': 1,...  \n",
       "7300   {'diffuse': 1, 'entire': 1, '\"': 2, 'hurt': 1,...  \n",
       "7299   {'diffuse': 1, 'entire': 1, '\"': 2, 'hurt': 1,...  \n",
       "7313   {'daughter': 1, 'need': 1, 'hot': 1, ''': 2, '...  \n",
       "7312   {'daughter': 1, 'need': 1, 'hot': 1, ''': 2, '...  \n",
       "\n",
       "[12000 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_tokens(tokens):\n",
    "    return dict(Counter(tokens))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"id\"]= final_df[\"id\"]\n",
    "df[\"text\"]= final_df[\"text\"]\n",
    "df[\"error_level\"] = final_df[\"error_level\"]\n",
    "df['token_counts'] = final_df['tokens'].apply(count_tokens)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
